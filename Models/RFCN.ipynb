{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RFCN.ipynb","provenance":[],"collapsed_sections":["GGZqihrPiBjs"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cTX19_zosgjz","colab_type":"code","colab":{}},"source":["\"\"\"The file needed to run this notebook can be accessed from the following folder using a UTS email account:\n","https://drive.google.com/drive/folders/1y6e1Z2SbLDKkmvK3-tyQ6INO5rrzT3jp\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mamiXm5pltDZ","colab_type":"text"},"source":["# Object Detection Using RFCN\n","\n","## Tutorial:\n","1. Image annotation using LabelImg\n","2. Conversion of annotation & images into tfrecords\n","3. Configuration of SSD config model file\n","4. Training the model\n","5. Using trained model for inference\n","\n","## Tasks for this week:\n","\n","1. installation of Google Object Detection API and required packages\n","2. Conversion of images and xml into tfrecord. i.e. train tfrecord, test tfrecord\n","3. Training: Transfer learning from already trained models\n","4. Freezing a trained model and export it for inference\n"]},{"cell_type":"markdown","metadata":{"id":"4IG-E4uMo8al","colab_type":"text"},"source":["##Task-1: Installation of Google Object Detection API and required packages\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CrgipiyWnlOF","colab_type":"text"},"source":["### Step 1: Import packages\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ADZ2V-GaMdo4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1592382207863,"user_tz":-600,"elapsed":3801,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"1fa84f6b-a8ca-470e-b0a2-62e25ffe1687"},"source":["%tensorflow_version 1.x \n","!pip install numpy==1.17.4"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Requirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.6/dist-packages (1.17.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cZzYq6qGXOUw","colab_type":"code","colab":{}},"source":["import os\n","import re\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XoB3GJU4Jv7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592382209088,"user_tz":-600,"elapsed":4997,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"61dbabf5-566b-4a86-9b5c-db76caa2ae48"},"source":["print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nmo5y3VQ6lax","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1592382212603,"user_tz":-600,"elapsed":8495,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"2c564f3e-30eb-474f-c1f1-8811611b68de"},"source":["pip install --upgrade tf_slim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\r\u001b[K     |█                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hgqx7vZnw4_W","colab_type":"text"},"source":["### Step 2: Initial Configuration to Select model config file and selection of other hyperparameters"]},{"cell_type":"code","metadata":{"id":"Gz2sswLyw9hZ","colab_type":"code","colab":{}},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/Tony607/object_detection_demo'\n","\n","# Number of training steps.\n","num_steps = 7000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 100\n","\n","MODELS_CONFIG = {\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","\n","selected_model = 'rfcn_resnet101'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXwYO33qxB2Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1592382218420,"user_tz":-600,"elapsed":12968,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"544c3030-6ed0-4380-f074-b0b9dbc1f504"},"source":["%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'object_detection_demo'...\n","remote: Enumerating objects: 124, done.\u001b[K\n","remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n","Receiving objects: 100% (124/124), 11.16 MiB | 36.39 MiB/s, done.\n","Resolving deltas: 100% (45/45), done.\n","/content/object_detection_demo\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5xTGEynaxUfL","colab_type":"text"},"source":["### Step 3: Download Google Object Detection API and other dependencies"]},{"cell_type":"code","metadata":{"id":"OerFd75RoIWz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592382258925,"user_tz":-600,"elapsed":52243,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"84aba041-55f6-4ac0-a9d1-5ee94ed7bd7a"},"source":["%cd /content\n","\n","#!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!git clone --branch r1.13.0 --depth 1 https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'models'...\n","remote: Enumerating objects: 2927, done.\u001b[K\n","remote: Counting objects: 100% (2927/2927), done.\u001b[K\n","remote: Compressing objects: 100% (2449/2449), done.\u001b[K\n","remote: Total 2927 (delta 509), reused 2035 (delta 403), pack-reused 0\u001b[K\n","Receiving objects: 100% (2927/2927), 369.04 MiB | 40.73 MiB/s, done.\n","Resolving deltas: 100% (509/509), done.\n","Checking out files: 100% (2768/2768), done.\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 144328 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","/content/models/research\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_embedded_ssd_mobilenet_v1_model_from_config\n","[       OK ] ModelBuilderTest.test_create_embedded_ssd_mobilenet_v1_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_inception_resnet_v2_model_from_config\n","WARNING:tensorflow:From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0617 08:24:17.768357 139871265372032 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_inception_resnet_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_inception_v2_model_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_inception_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_nas_model_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_nas_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_pnas_model_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_pnas_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=False)\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=False)\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=True)\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_resnet101_with_mask_prediction_enabled(use_matmul_crop_and_resize=True)\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_resnet_v1_models_from_config\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_resnet_v1_models_from_config\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_resnet_v1_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_resnet_v1_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_inception_v2_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_inception_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_inception_v3_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_inception_v3_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v1_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v1_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v1_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v1_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v1_ppn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v1_ppn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpnlite_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_fpnlite_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_keras_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_keras_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_mobilenet_v2_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_mobilenet_v2_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_resnet_v1_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_resnet_v1_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_resnet_v1_ppn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_resnet_v1_ppn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","----------------------------------------------------------------------\n","Ran 22 tests in 0.101s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xl2Xn4Mh0bqw","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"IsXk9v7fRYFM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1592382294755,"user_tz":-600,"elapsed":86812,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"21953bc8-adad-4103-bd96-979ff9d16001"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uBOCW--vh6Wn","colab_type":"text"},"source":["##Task-2: Conversion of XML annotations and images into tfrecords for training and testing datasets"]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny","colab_type":"text"},"source":["### Step 4: Prepare `tfrecord` files\n","\n","Use the following scripts to generate the `tfrecord` files.\n","```bash\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n","```"]},{"cell_type":"code","metadata":{"id":"kTqzzSJAj2MB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592248802205,"user_tz":-420,"elapsed":57146,"user":{"displayName":"Thi Thu Le","photoUrl":"","userId":"15349769042236436170"}},"outputId":"b96d200e-c25b-4f76-e2b4-4a7ee2611858"},"source":["#create the annotation directory\n","%cd /content/object_detection_demo/data\n","annotation_dir = 'annotations/'\n","os.makedirs(annotation_dir, exist_ok=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/object_detection_demo/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HfYP0Rd_tLYE","colab_type":"code","colab":{}},"source":["\"\"\"Need to manually upload  the label_pbtxt file and the train_labels.csv and test_labels.csv\n","into the annotation folder using the link here\n","https://drive.google.com/drive/folders/1NqKz2tC8I5eL5Qo4YzZiEph8W-dtI44d\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmpbbeIKiHjr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1592227029995,"user_tz":-600,"elapsed":6386110,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"74221794-2080-4ae6-9e1a-5d8fc8353ac4"},"source":["%cd /content/gdrive/My Drive/A3 test\n","# Generate `train.record`\n","!python generate_tfrecord.py --csv_input=train_csv/train_labels.csv --output_path=annotations/train.record --img_path=train --label_map annotations/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/A3 test\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0615 11:30:48.504616 140182534674304 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0615 11:30:49.260015 140182534674304 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/gdrive/My Drive/A3 test/annotations/train.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0tLBgcWTuslH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1592228672072,"user_tz":-600,"elapsed":7269179,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"bc702358-43ef-4f1f-83ef-461b3f3e5fd4"},"source":["%cd /content/gdrive/My Drive/A3 test\n","# Generate `test.record`\n","!python generate_tfrecord.py --csv_input=test_csv/test_labels.csv --output_path=annotations/test.record --img_path=test --label_map annotations/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/A3 test\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0615 13:17:13.488225 140325260527488 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0615 13:17:15.261747 140325260527488 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/gdrive/My Drive/A3 test/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c24vw09_5jNI","colab_type":"code","colab":{}},"source":["test_record_fname = '/content/gdrive/My Drive/A3 test/annotations/test.record'\n","train_record_fname = '/content/gdrive/My Drive/A3 test/annotations/train.record'\n","label_map_pbtxt_fname = '/content/gdrive/My Drive/A3 test/annotations/label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGZqihrPiBjs","colab_type":"text"},"source":["### Step 5. Download the base model for transfer learning"]},{"cell_type":"code","metadata":{"id":"jj7_kqv6yR7D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592382335375,"user_tz":-600,"elapsed":9520,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"3354a4cb-7ae5-474b-dd28-b38dd00c3fe0"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zhsMMfNN25hY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1592382346082,"user_tz":-600,"elapsed":3867,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"96894265-18d8-4baa-ae59-4093269e9960"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 476M\n","drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n","drwxr-xr-x 70 root   root 4.0K Jun 17 08:25 ..\n","-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n","-rw-r--r--  1 345018 5000 208M Feb  1  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 5000 262M Feb  1  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 5000  26K Feb  1  2018 model.ckpt.index\n","-rw-r--r--  1 345018 5000 6.4M Feb  1  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 5000 3.1K Feb  1  2018 pipeline.config\n","drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gs0047Qx4LIf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592382361746,"user_tz":-600,"elapsed":734,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"f0606b0c-e7bf-4a1c-c955-5c543e5c87d0"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"GTJvAARCiQbm","colab_type":"text"},"source":["##Task-3: Training: Transfer learning from already trained models\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-BWSpqW6NYJE","colab_type":"text"},"source":["###Step 6: configuring a training pipeline"]},{"cell_type":"code","metadata":{"id":"551Z4gAC4uzO","colab_type":"code","colab":{}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZYoq1tq40Ak","colab_type":"code","colab":{}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"098IARSk5CJk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1592382382428,"user_tz":-600,"elapsed":1257,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"72317f13-12e6-48fd-f3c2-a8d137b23cbb"},"source":["\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LW5OvToX5v3Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592382392461,"user_tz":-600,"elapsed":2083,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"d93b85ec-94ae-493a-ccaa-1dc3d8e9c3f2"},"source":["!cat {pipeline_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# R-FCN with Resnet-101 (v1),  configured for Oxford-IIIT Pets Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 1\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 600\n","        max_dimension: 1024\n","      }\n","    }\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet101'\n","      first_stage_features_stride: 16\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    second_stage_box_predictor {\n","      rfcn_box_predictor {\n","        conv_hyperparams {\n","          op: CONV\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.01\n","            }\n","          }\n","        }\n","        crop_height: 18\n","        crop_width: 18\n","        num_spatial_bins_height: 3\n","        num_spatial_bins_width: 3\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.0\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 300\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 8\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 900000\n","            learning_rate: .00003\n","          }\n","          schedule {\n","            step: 1200000\n","            learning_rate: .000003\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  gradient_clipping_by_norm: 10.0\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  from_detection_checkpoint: true\n","  load_all_detection_checkpoint_vars: true\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 1000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/A3 test/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/gdrive/My Drive/A3 test/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  num_examples: 1101\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/A3 test/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/gdrive/My Drive/A3 test/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wOzfAVox6DxP","colab_type":"code","colab":{}},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeXwrBbnibPp","colab_type":"text"},"source":["### Step 7. Install Tensorboard to visualize the progress of training process"]},{"cell_type":"code","metadata":{"id":"JY2IwBMvyiLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1592384345448,"user_tz":-600,"elapsed":9505,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"70dfb412-cbd7-46f8-8433-809aa671c759"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-17 08:58:59--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 54.164.74.108, 54.161.19.10, 34.233.91.203, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|54.164.74.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  43%[=======>            ]   5.66M  27.6MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  42.5MB/s    in 0.3s    \n","\n","2020-06-17 08:58:59 (42.5 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gPSCe4VW6is7","colab_type":"code","colab":{}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NcQjIax6oSu","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LfI4vNaj6zgs","colab_type":"text"},"source":["### Step: 8 Get tensorboard link"]},{"cell_type":"code","metadata":{"id":"-26O0PrC6x2O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592384356643,"user_tz":-600,"elapsed":5387,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"e844c269-eec0-4e35-836d-71f9d0f45634"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://19e630cb7971.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"STof3OBrdWUy","colab_type":"text"},"source":["### Step 9.  Training the model"]},{"cell_type":"code","metadata":{"id":"PZSdysPLcfOA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592393309317,"user_tz":-600,"elapsed":6162647,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"1f8ef8af-4721-40d3-d03d-2de44eb2d06b"},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0617 08:59:21.863340 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0617 08:59:21.865852 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0617 08:59:21.866010 140626870351744 model_lib.py:574] Forced number of epochs for all eval validations to be 1.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0617 08:59:21.866147 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:Maybe overwriting train_steps: 7000\n","I0617 08:59:21.866232 140626870351744 config_util.py:480] Maybe overwriting train_steps: 7000\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0617 08:59:21.866317 140626870351744 config_util.py:480] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0617 08:59:21.866399 140626870351744 config_util.py:480] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0617 08:59:21.866472 140626870351744 config_util.py:480] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0617 08:59:21.866549 140626870351744 config_util.py:490] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0617 08:59:21.867143 140626870351744 model_lib.py:590] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0617 08:59:21.867240 140626870351744 model_lib.py:623] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe5d6895588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0617 08:59:21.867614 140626870351744 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe5d6895588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe5d68a50d0>) includes params argument, but params are not passed to Estimator.\n","W0617 08:59:21.867815 140626870351744 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe5d68a50d0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0617 08:59:21.868472 140626870351744 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0617 08:59:21.868666 140626870351744 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0617 08:59:21.868875 140626870351744 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0617 08:59:21.873651 140626870351744 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:167: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0617 08:59:21.882289 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:167: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0617 08:59:21.882538 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0617 08:59:21.904967 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:61: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0617 08:59:21.906369 140626870351744 dataset_builder.py:66] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0617 08:59:21.912718 140626870351744 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0617 08:59:21.912866 140626870351744 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe600046ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 08:59:21.950588 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe600046ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","2020-06-17 08:59:21.976817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-17 08:59:21.982922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:21.983375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 08:59:21.983664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 08:59:21.985343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 08:59:21.987073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 08:59:21.987377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 08:59:21.989398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 08:59:21.990572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 08:59:21.994203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 08:59:21.994336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:21.994838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:21.995264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0617 08:59:22.080037 140626870351744 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:466: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0617 08:59:22.082286 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/utils/ops.py:466: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:466: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0617 08:59:22.082828 140626870351744 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:466: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:468: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0617 08:59:22.085090 140626870351744 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:468: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0617 08:59:22.100084 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0617 08:59:22.145589 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:374: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","W0617 08:59:22.338199 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:374: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","W0617 08:59:22.362221 140626870351744 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","INFO:tensorflow:Calling model_fn.\n","I0617 08:59:22.373571 140626870351744 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0617 08:59:22.472047 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 08:59:22.479800 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0617 08:59:22.482516 140626870351744 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0617 08:59:25.302015 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 08:59:25.308074 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","W0617 08:59:25.308407 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 08:59:25.320410 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 08:59:25.320721 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0617 08:59:25.953444 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/minibatch_sampler.py:81: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","W0617 08:59:25.994459 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/core/minibatch_sampler.py:81: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:185: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","W0617 08:59:27.708463 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:185: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 08:59:27.708845 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 08:59:27.955544 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:712: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0617 08:59:28.062154 140626870351744 deprecation.py:506] From /content/models/research/object_detection/utils/ops.py:712: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use the `axis` argument instead\n","W0617 08:59:28.965998 140626870351744 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use the `axis` argument instead\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2235: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","W0617 08:59:30.017379 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2235: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2236: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0617 08:59:30.017659 140626870351744 deprecation.py:323] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2236: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:126: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0617 08:59:30.019203 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:126: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0617 08:59:30.025380 140626870351744 variables_helper.py:141] Variable [SecondStageBoxPredictor/class_predictions/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[819]], model variable shape: [[18]]. This variable will not be initialized from the checkpoint.\n","W0617 08:59:30.025501 140626870351744 variables_helper.py:141] Variable [SecondStageBoxPredictor/class_predictions/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 819]], model variable shape: [[1, 1, 1024, 18]]. This variable will not be initialized from the checkpoint.\n","W0617 08:59:30.025596 140626870351744 variables_helper.py:141] Variable [SecondStageBoxPredictor/refined_locations/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[3240]], model variable shape: [[36]]. This variable will not be initialized from the checkpoint.\n","W0617 08:59:30.025660 140626870351744 variables_helper.py:141] Variable [SecondStageBoxPredictor/refined_locations/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 3240]], model variable shape: [[1, 1, 1024, 36]]. This variable will not be initialized from the checkpoint.\n","W0617 08:59:30.026115 140626870351744 variables_helper.py:144] Variable [global_step] is not available in checkpoint\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:317: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0617 08:59:30.026358 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:317: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0617 08:59:33.014684 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:174: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0617 08:59:33.015892 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:180: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0617 08:59:33.055978 140626870351744 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2202: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","W0617 08:59:33.974540 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2202: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:341: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0617 08:59:33.975373 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:341: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:52: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","W0617 08:59:33.981831 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:52: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:359: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0617 08:59:33.982042 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:359: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:369: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0617 08:59:33.982224 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:369: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:472: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0617 08:59:46.443725 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:472: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:476: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0617 08:59:47.040690 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:476: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:477: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0617 08:59:47.040978 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:477: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0617 08:59:47.041309 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0617 08:59:47.042503 140626870351744 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0617 08:59:51.798773 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 08:59:51.803382: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-06-17 08:59:51.803574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23cfe140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-17 08:59:51.803617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-17 08:59:51.893444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:51.894035: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23cfdf80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-17 08:59:51.894065: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-17 08:59:51.894280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:51.894685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 08:59:51.894770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 08:59:51.894800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 08:59:51.894823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 08:59:51.894848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 08:59:51.894875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 08:59:51.894956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 08:59:51.894981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 08:59:51.895093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:51.895573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:51.895989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 08:59:51.896077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 08:59:51.897216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 08:59:51.897244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 08:59:51.897260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 08:59:51.897399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:51.897884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 08:59:51.898306: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-17 08:59:51.898347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","2020-06-17 08:59:53.257361: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n","2020-06-17 08:59:53.489043: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n","2020-06-17 08:59:53.590403: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n","2020-06-17 08:59:53.733096: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n","2020-06-17 08:59:53.885851: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\n","INFO:tensorflow:Running local_init_op.\n","I0617 09:00:00.900222 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 09:00:01.451279 140626870351744 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n","I0617 09:00:15.509456 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n","2020-06-17 09:00:31.189864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 09:00:32.338569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 09:00:33.547223: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","INFO:tensorflow:loss = 1.2842872, step = 0\n","I0617 09:00:34.836959 140626870351744 basic_session_run_hooks.py:262] loss = 1.2842872, step = 0\n","INFO:tensorflow:global_step/sec: 1.15895\n","I0617 09:02:01.121223 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.15895\n","INFO:tensorflow:loss = 1.0294284, step = 100 (86.285 sec)\n","I0617 09:02:01.122241 140626870351744 basic_session_run_hooks.py:260] loss = 1.0294284, step = 100 (86.285 sec)\n","INFO:tensorflow:global_step/sec: 1.27762\n","I0617 09:03:19.391921 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27762\n","INFO:tensorflow:loss = 0.6777348, step = 200 (78.271 sec)\n","I0617 09:03:19.393183 140626870351744 basic_session_run_hooks.py:260] loss = 0.6777348, step = 200 (78.271 sec)\n","INFO:tensorflow:global_step/sec: 1.28119\n","I0617 09:04:37.444211 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28119\n","INFO:tensorflow:loss = 0.98728716, step = 300 (78.052 sec)\n","I0617 09:04:37.445399 140626870351744 basic_session_run_hooks.py:260] loss = 0.98728716, step = 300 (78.052 sec)\n","INFO:tensorflow:global_step/sec: 1.28246\n","I0617 09:05:55.419322 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28246\n","INFO:tensorflow:loss = 0.5429901, step = 400 (77.975 sec)\n","I0617 09:05:55.420380 140626870351744 basic_session_run_hooks.py:260] loss = 0.5429901, step = 400 (77.975 sec)\n","INFO:tensorflow:global_step/sec: 1.27961\n","I0617 09:07:13.567983 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27961\n","INFO:tensorflow:loss = 0.5978362, step = 500 (78.149 sec)\n","I0617 09:07:13.569166 140626870351744 basic_session_run_hooks.py:260] loss = 0.5978362, step = 500 (78.149 sec)\n","INFO:tensorflow:global_step/sec: 1.27349\n","I0617 09:08:32.092286 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27349\n","INFO:tensorflow:loss = 0.8104238, step = 600 (78.524 sec)\n","I0617 09:08:32.093363 140626870351744 basic_session_run_hooks.py:260] loss = 0.8104238, step = 600 (78.524 sec)\n","INFO:tensorflow:global_step/sec: 1.27917\n","I0617 09:09:50.268033 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27917\n","INFO:tensorflow:loss = 0.67875326, step = 700 (78.176 sec)\n","I0617 09:09:50.269144 140626870351744 basic_session_run_hooks.py:260] loss = 0.67875326, step = 700 (78.176 sec)\n","INFO:tensorflow:Saving checkpoints for 740 into training/model.ckpt.\n","I0617 09:10:20.747971 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 740 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe5777c3d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 09:10:24.390253 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe5777c3d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 09:10:24.820141 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:10:24.846549 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:10:27.646597 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:10:27.658954 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 09:10:27.659282 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:10:28.101971 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:10:28.369542 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:750: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0617 09:10:29.632938 140626870351744 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:750: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0617 09:10:29.776114 140626870351744 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","W0617 09:10:29.903468 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/utils/visualization_utils.py:924: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:441: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0617 09:10:29.985230 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:441: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0617 09:10:30.435026 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T09:10:30Z\n","I0617 09:10:30.450091 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T09:10:30Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 09:10:31.096575 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 09:10:31.097829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:10:31.098147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 09:10:31.098243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 09:10:31.098275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 09:10:31.098298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 09:10:31.098321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 09:10:31.098350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 09:10:31.098370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 09:10:31.098391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 09:10:31.098507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:10:31.098810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:10:31.099041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 09:10:31.099087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 09:10:31.099101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 09:10:31.099110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 09:10:31.099237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:10:31.099534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:10:31.099766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-740\n","I0617 09:10:31.100923 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-740\n","INFO:tensorflow:Running local_init_op.\n","I0617 09:10:32.668555 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 09:10:32.844949 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 09:13:44.367871 140623421343488 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.41s)\n","I0617 09:13:44.781075 140623421343488 coco_tools.py:131] DONE (t=0.41s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.79s).\n","Accumulating evaluation results...\n","DONE (t=2.61s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.365\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.271\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.543\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593\n","INFO:tensorflow:Finished evaluation at 2020-06-17-09:14:04\n","I0617 09:14:04.979043 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-09:14:04\n","INFO:tensorflow:Saving dict for global step 740: DetectionBoxes_Precision/mAP = 0.3520298, DetectionBoxes_Precision/mAP (large) = 0.0037690396, DetectionBoxes_Precision/mAP (medium) = 0.27408546, DetectionBoxes_Precision/mAP (small) = 0.3652042, DetectionBoxes_Precision/mAP@.50IOU = 0.72577006, DetectionBoxes_Precision/mAP@.75IOU = 0.28301588, DetectionBoxes_Recall/AR@1 = 0.27051204, DetectionBoxes_Recall/AR@10 = 0.5068205, DetectionBoxes_Recall/AR@100 = 0.54826957, DetectionBoxes_Recall/AR@100 (large) = 0.5933333, DetectionBoxes_Recall/AR@100 (medium) = 0.5827011, DetectionBoxes_Recall/AR@100 (small) = 0.5427835, Loss/BoxClassifierLoss/classification_loss = 0.16743542, Loss/BoxClassifierLoss/localization_loss = 0.12594679, Loss/RPNLoss/localization_loss = 0.030730719, Loss/RPNLoss/objectness_loss = 0.048275594, Loss/total_loss = 0.3723893, global_step = 740, learning_rate = 0.0003, loss = 0.3723893\n","I0617 09:14:04.979321 140626870351744 estimator.py:2049] Saving dict for global step 740: DetectionBoxes_Precision/mAP = 0.3520298, DetectionBoxes_Precision/mAP (large) = 0.0037690396, DetectionBoxes_Precision/mAP (medium) = 0.27408546, DetectionBoxes_Precision/mAP (small) = 0.3652042, DetectionBoxes_Precision/mAP@.50IOU = 0.72577006, DetectionBoxes_Precision/mAP@.75IOU = 0.28301588, DetectionBoxes_Recall/AR@1 = 0.27051204, DetectionBoxes_Recall/AR@10 = 0.5068205, DetectionBoxes_Recall/AR@100 = 0.54826957, DetectionBoxes_Recall/AR@100 (large) = 0.5933333, DetectionBoxes_Recall/AR@100 (medium) = 0.5827011, DetectionBoxes_Recall/AR@100 (small) = 0.5427835, Loss/BoxClassifierLoss/classification_loss = 0.16743542, Loss/BoxClassifierLoss/localization_loss = 0.12594679, Loss/RPNLoss/localization_loss = 0.030730719, Loss/RPNLoss/objectness_loss = 0.048275594, Loss/total_loss = 0.3723893, global_step = 740, learning_rate = 0.0003, loss = 0.3723893\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 740: training/model.ckpt-740\n","I0617 09:14:06.360345 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 740: training/model.ckpt-740\n","INFO:tensorflow:global_step/sec: 0.329217\n","I0617 09:14:54.018674 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.329217\n","INFO:tensorflow:loss = 0.56714493, step = 800 (303.751 sec)\n","I0617 09:14:54.019799 140626870351744 basic_session_run_hooks.py:260] loss = 0.56714493, step = 800 (303.751 sec)\n","INFO:tensorflow:global_step/sec: 1.27726\n","I0617 09:16:12.311033 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27726\n","INFO:tensorflow:loss = 0.8179549, step = 900 (78.292 sec)\n","I0617 09:16:12.311942 140626870351744 basic_session_run_hooks.py:260] loss = 0.8179549, step = 900 (78.292 sec)\n","INFO:tensorflow:global_step/sec: 1.27734\n","I0617 09:17:30.598580 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27734\n","INFO:tensorflow:loss = 0.86686635, step = 1000 (78.288 sec)\n","I0617 09:17:30.599659 140626870351744 basic_session_run_hooks.py:260] loss = 0.86686635, step = 1000 (78.288 sec)\n","INFO:tensorflow:global_step/sec: 1.28232\n","I0617 09:18:48.582268 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28232\n","INFO:tensorflow:loss = 0.84696764, step = 1100 (77.984 sec)\n","I0617 09:18:48.583457 140626870351744 basic_session_run_hooks.py:260] loss = 0.84696764, step = 1100 (77.984 sec)\n","INFO:tensorflow:global_step/sec: 1.27999\n","I0617 09:20:06.707943 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27999\n","INFO:tensorflow:loss = 0.71004313, step = 1200 (78.126 sec)\n","I0617 09:20:06.709124 140626870351744 basic_session_run_hooks.py:260] loss = 0.71004313, step = 1200 (78.126 sec)\n","INFO:tensorflow:Saving checkpoints for 1220 into training/model.ckpt.\n","I0617 09:20:21.487435 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 1220 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe544d691e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 09:20:24.906744 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe544d691e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 09:20:25.324669 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:20:25.350851 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:20:28.106223 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:20:28.118914 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 09:20:28.119272 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:20:28.579399 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:20:28.852126 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 09:20:30.655715 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T09:20:30Z\n","I0617 09:20:30.671284 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T09:20:30Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 09:20:31.329827 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 09:20:31.330490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:20:31.330830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 09:20:31.334350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 09:20:31.334425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 09:20:31.334451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 09:20:31.334472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 09:20:31.334497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 09:20:31.334516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 09:20:31.334537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 09:20:31.334656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:20:31.335003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:20:31.335233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 09:20:31.335273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 09:20:31.335286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 09:20:31.335297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 09:20:31.335410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:20:31.335758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:20:31.336045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-1220\n","I0617 09:20:31.337135 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-1220\n","INFO:tensorflow:Running local_init_op.\n","I0617 09:20:32.873651 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 09:20:33.051122 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 09:23:43.933980 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.42s)\n","I0617 09:23:44.351923 140623412950784 coco_tools.py:131] DONE (t=0.42s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=17.07s).\n","Accumulating evaluation results...\n","DONE (t=2.45s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.366\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.548\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n","INFO:tensorflow:Finished evaluation at 2020-06-17-09:24:04\n","I0617 09:24:04.661056 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-09:24:04\n","INFO:tensorflow:Saving dict for global step 1220: DetectionBoxes_Precision/mAP = 0.35685897, DetectionBoxes_Precision/mAP (large) = 0.008658241, DetectionBoxes_Precision/mAP (medium) = 0.30155215, DetectionBoxes_Precision/mAP (small) = 0.366362, DetectionBoxes_Precision/mAP@.50IOU = 0.7372937, DetectionBoxes_Precision/mAP@.75IOU = 0.28186038, DetectionBoxes_Recall/AR@1 = 0.2738717, DetectionBoxes_Recall/AR@10 = 0.51471364, DetectionBoxes_Recall/AR@100 = 0.55549484, DetectionBoxes_Recall/AR@100 (large) = 0.64666665, DetectionBoxes_Recall/AR@100 (medium) = 0.60257965, DetectionBoxes_Recall/AR@100 (small) = 0.54789126, Loss/BoxClassifierLoss/classification_loss = 0.15842967, Loss/BoxClassifierLoss/localization_loss = 0.12616444, Loss/RPNLoss/localization_loss = 0.03001606, Loss/RPNLoss/objectness_loss = 0.047681384, Loss/total_loss = 0.36229149, global_step = 1220, learning_rate = 0.0003, loss = 0.36229149\n","I0617 09:24:04.661330 140626870351744 estimator.py:2049] Saving dict for global step 1220: DetectionBoxes_Precision/mAP = 0.35685897, DetectionBoxes_Precision/mAP (large) = 0.008658241, DetectionBoxes_Precision/mAP (medium) = 0.30155215, DetectionBoxes_Precision/mAP (small) = 0.366362, DetectionBoxes_Precision/mAP@.50IOU = 0.7372937, DetectionBoxes_Precision/mAP@.75IOU = 0.28186038, DetectionBoxes_Recall/AR@1 = 0.2738717, DetectionBoxes_Recall/AR@10 = 0.51471364, DetectionBoxes_Recall/AR@100 = 0.55549484, DetectionBoxes_Recall/AR@100 (large) = 0.64666665, DetectionBoxes_Recall/AR@100 (medium) = 0.60257965, DetectionBoxes_Recall/AR@100 (small) = 0.54789126, Loss/BoxClassifierLoss/classification_loss = 0.15842967, Loss/BoxClassifierLoss/localization_loss = 0.12616444, Loss/RPNLoss/localization_loss = 0.03001606, Loss/RPNLoss/objectness_loss = 0.047681384, Loss/total_loss = 0.36229149, global_step = 1220, learning_rate = 0.0003, loss = 0.36229149\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1220: training/model.ckpt-1220\n","I0617 09:24:04.662253 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1220: training/model.ckpt-1220\n","INFO:tensorflow:global_step/sec: 0.331985\n","I0617 09:25:07.926794 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.331985\n","INFO:tensorflow:loss = 0.8144297, step = 1300 (301.219 sec)\n","I0617 09:25:07.928003 140626870351744 basic_session_run_hooks.py:260] loss = 0.8144297, step = 1300 (301.219 sec)\n","INFO:tensorflow:global_step/sec: 1.27764\n","I0617 09:26:26.195883 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27764\n","INFO:tensorflow:loss = 0.6396644, step = 1400 (78.269 sec)\n","I0617 09:26:26.196999 140626870351744 basic_session_run_hooks.py:260] loss = 0.6396644, step = 1400 (78.269 sec)\n","INFO:tensorflow:global_step/sec: 1.27942\n","I0617 09:27:44.356273 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27942\n","INFO:tensorflow:loss = 0.6347585, step = 1500 (78.161 sec)\n","I0617 09:27:44.357638 140626870351744 basic_session_run_hooks.py:260] loss = 0.6347585, step = 1500 (78.161 sec)\n","INFO:tensorflow:global_step/sec: 1.28446\n","I0617 09:29:02.209960 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28446\n","INFO:tensorflow:loss = 0.5337739, step = 1600 (77.854 sec)\n","I0617 09:29:02.211152 140626870351744 basic_session_run_hooks.py:260] loss = 0.5337739, step = 1600 (77.854 sec)\n","INFO:tensorflow:global_step/sec: 1.2822\n","I0617 09:30:20.200606 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.2822\n","INFO:tensorflow:loss = 0.58396643, step = 1700 (77.991 sec)\n","I0617 09:30:20.201816 140626870351744 basic_session_run_hooks.py:260] loss = 0.58396643, step = 1700 (77.991 sec)\n","INFO:tensorflow:Saving checkpoints for 1703 into training/model.ckpt.\n","I0617 09:30:21.796528 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 1703 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe287ca58c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 09:30:25.373097 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe287ca58c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 09:30:25.799632 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:30:25.826008 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:30:28.565258 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:30:28.577458 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 09:30:28.577781 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:30:29.031926 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:30:29.280940 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 09:30:31.076331 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T09:30:31Z\n","I0617 09:30:31.091609 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T09:30:31Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 09:30:31.744259 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 09:30:31.744969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:30:31.745268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 09:30:31.745364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 09:30:31.745387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 09:30:31.745428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 09:30:31.745448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 09:30:31.745468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 09:30:31.745491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 09:30:31.745515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 09:30:31.745640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:30:31.745967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:30:31.746252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 09:30:31.746351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 09:30:31.746365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 09:30:31.746374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 09:30:31.746512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:30:31.746860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:30:31.747126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-1703\n","I0617 09:30:31.748381 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-1703\n","INFO:tensorflow:Running local_init_op.\n","I0617 09:30:33.341835 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 09:30:33.520303 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 09:33:46.702319 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.39s)\n","I0617 09:33:47.091455 140623412950784 coco_tools.py:131] DONE (t=0.39s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.78s).\n","Accumulating evaluation results...\n","DONE (t=2.49s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.541\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n","INFO:tensorflow:Finished evaluation at 2020-06-17-09:34:07\n","I0617 09:34:07.117709 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-09:34:07\n","INFO:tensorflow:Saving dict for global step 1703: DetectionBoxes_Precision/mAP = 0.35026354, DetectionBoxes_Precision/mAP (large) = 0.004158835, DetectionBoxes_Precision/mAP (medium) = 0.29302272, DetectionBoxes_Precision/mAP (small) = 0.3594482, DetectionBoxes_Precision/mAP@.50IOU = 0.7376348, DetectionBoxes_Precision/mAP@.75IOU = 0.25429454, DetectionBoxes_Recall/AR@1 = 0.26711193, DetectionBoxes_Recall/AR@10 = 0.5049788, DetectionBoxes_Recall/AR@100 = 0.54691356, DetectionBoxes_Recall/AR@100 (large) = 0.6066667, DetectionBoxes_Recall/AR@100 (medium) = 0.5861912, DetectionBoxes_Recall/AR@100 (small) = 0.5406514, Loss/BoxClassifierLoss/classification_loss = 0.15746221, Loss/BoxClassifierLoss/localization_loss = 0.13000645, Loss/RPNLoss/localization_loss = 0.029511813, Loss/RPNLoss/objectness_loss = 0.04767628, Loss/total_loss = 0.36465728, global_step = 1703, learning_rate = 0.0003, loss = 0.36465728\n","I0617 09:34:07.118010 140626870351744 estimator.py:2049] Saving dict for global step 1703: DetectionBoxes_Precision/mAP = 0.35026354, DetectionBoxes_Precision/mAP (large) = 0.004158835, DetectionBoxes_Precision/mAP (medium) = 0.29302272, DetectionBoxes_Precision/mAP (small) = 0.3594482, DetectionBoxes_Precision/mAP@.50IOU = 0.7376348, DetectionBoxes_Precision/mAP@.75IOU = 0.25429454, DetectionBoxes_Recall/AR@1 = 0.26711193, DetectionBoxes_Recall/AR@10 = 0.5049788, DetectionBoxes_Recall/AR@100 = 0.54691356, DetectionBoxes_Recall/AR@100 (large) = 0.6066667, DetectionBoxes_Recall/AR@100 (medium) = 0.5861912, DetectionBoxes_Recall/AR@100 (small) = 0.5406514, Loss/BoxClassifierLoss/classification_loss = 0.15746221, Loss/BoxClassifierLoss/localization_loss = 0.13000645, Loss/RPNLoss/localization_loss = 0.029511813, Loss/RPNLoss/objectness_loss = 0.04767628, Loss/total_loss = 0.36465728, global_step = 1703, learning_rate = 0.0003, loss = 0.36465728\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1703: training/model.ckpt-1703\n","I0617 09:34:07.118947 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1703: training/model.ckpt-1703\n","INFO:tensorflow:global_step/sec: 0.329614\n","I0617 09:35:23.585869 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.329614\n","INFO:tensorflow:loss = 0.39880756, step = 1800 (303.385 sec)\n","I0617 09:35:23.587078 140626870351744 basic_session_run_hooks.py:260] loss = 0.39880756, step = 1800 (303.385 sec)\n","INFO:tensorflow:global_step/sec: 1.2803\n","I0617 09:36:41.692876 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.2803\n","INFO:tensorflow:loss = 0.6437082, step = 1900 (78.107 sec)\n","I0617 09:36:41.693930 140626870351744 basic_session_run_hooks.py:260] loss = 0.6437082, step = 1900 (78.107 sec)\n","INFO:tensorflow:global_step/sec: 1.28162\n","I0617 09:37:59.719313 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28162\n","INFO:tensorflow:loss = 0.52580047, step = 2000 (78.027 sec)\n","I0617 09:37:59.720531 140626870351744 basic_session_run_hooks.py:260] loss = 0.52580047, step = 2000 (78.027 sec)\n","INFO:tensorflow:global_step/sec: 1.28054\n","I0617 09:39:17.811200 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28054\n","INFO:tensorflow:loss = 0.47870368, step = 2100 (78.092 sec)\n","I0617 09:39:17.812336 140626870351744 basic_session_run_hooks.py:260] loss = 0.47870368, step = 2100 (78.092 sec)\n","INFO:tensorflow:Saving checkpoints for 2183 into training/model.ckpt.\n","I0617 09:40:21.879032 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 2183 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe544d691e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 09:40:25.486286 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe544d691e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 09:40:25.908287 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:40:25.934057 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:40:28.676135 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:40:28.689437 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 09:40:28.689810 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:40:29.132376 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:40:29.388623 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 09:40:31.149473 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T09:40:31Z\n","I0617 09:40:31.164891 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T09:40:31Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 09:40:31.828331 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 09:40:31.829034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:40:31.829340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 09:40:31.829435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 09:40:31.829464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 09:40:31.829486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 09:40:31.829511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 09:40:31.829532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 09:40:31.829551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 09:40:31.829594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 09:40:31.829711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:40:31.830050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:40:31.830281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 09:40:31.830322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 09:40:31.830336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 09:40:31.830345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 09:40:31.830476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:40:31.830789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:40:31.831030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-2183\n","I0617 09:40:31.832103 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-2183\n","INFO:tensorflow:Running local_init_op.\n","I0617 09:40:33.404684 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 09:40:33.591391 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 09:43:45.055660 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.41s)\n","I0617 09:43:45.467858 140623412950784 coco_tools.py:131] DONE (t=0.41s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=17.05s).\n","Accumulating evaluation results...\n","DONE (t=2.48s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.271\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.511\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.547\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n","INFO:tensorflow:Finished evaluation at 2020-06-17-09:44:05\n","I0617 09:44:05.756256 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-09:44:05\n","INFO:tensorflow:Saving dict for global step 2183: DetectionBoxes_Precision/mAP = 0.3604455, DetectionBoxes_Precision/mAP (large) = 0.011444105, DetectionBoxes_Precision/mAP (medium) = 0.30338308, DetectionBoxes_Precision/mAP (small) = 0.36952958, DetectionBoxes_Precision/mAP@.50IOU = 0.74166983, DetectionBoxes_Precision/mAP@.75IOU = 0.2879663, DetectionBoxes_Recall/AR@1 = 0.2714835, DetectionBoxes_Recall/AR@10 = 0.51096946, DetectionBoxes_Recall/AR@100 = 0.5541591, DetectionBoxes_Recall/AR@100 (large) = 0.61333334, DetectionBoxes_Recall/AR@100 (medium) = 0.6019727, DetectionBoxes_Recall/AR@100 (small) = 0.54653233, Loss/BoxClassifierLoss/classification_loss = 0.16684356, Loss/BoxClassifierLoss/localization_loss = 0.12683329, Loss/RPNLoss/localization_loss = 0.02912238, Loss/RPNLoss/objectness_loss = 0.045558438, Loss/total_loss = 0.36835736, global_step = 2183, learning_rate = 0.0003, loss = 0.36835736\n","I0617 09:44:05.756548 140626870351744 estimator.py:2049] Saving dict for global step 2183: DetectionBoxes_Precision/mAP = 0.3604455, DetectionBoxes_Precision/mAP (large) = 0.011444105, DetectionBoxes_Precision/mAP (medium) = 0.30338308, DetectionBoxes_Precision/mAP (small) = 0.36952958, DetectionBoxes_Precision/mAP@.50IOU = 0.74166983, DetectionBoxes_Precision/mAP@.75IOU = 0.2879663, DetectionBoxes_Recall/AR@1 = 0.2714835, DetectionBoxes_Recall/AR@10 = 0.51096946, DetectionBoxes_Recall/AR@100 = 0.5541591, DetectionBoxes_Recall/AR@100 (large) = 0.61333334, DetectionBoxes_Recall/AR@100 (medium) = 0.6019727, DetectionBoxes_Recall/AR@100 (small) = 0.54653233, Loss/BoxClassifierLoss/classification_loss = 0.16684356, Loss/BoxClassifierLoss/localization_loss = 0.12683329, Loss/RPNLoss/localization_loss = 0.02912238, Loss/RPNLoss/objectness_loss = 0.045558438, Loss/total_loss = 0.36835736, global_step = 2183, learning_rate = 0.0003, loss = 0.36835736\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2183: training/model.ckpt-2183\n","I0617 09:44:05.757560 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2183: training/model.ckpt-2183\n","INFO:tensorflow:global_step/sec: 0.331151\n","I0617 09:44:19.788629 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.331151\n","INFO:tensorflow:loss = 0.59743804, step = 2200 (301.977 sec)\n","I0617 09:44:19.789802 140626870351744 basic_session_run_hooks.py:260] loss = 0.59743804, step = 2200 (301.977 sec)\n","INFO:tensorflow:global_step/sec: 1.27972\n","I0617 09:45:37.930451 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27972\n","INFO:tensorflow:loss = 0.60676545, step = 2300 (78.142 sec)\n","I0617 09:45:37.931393 140626870351744 basic_session_run_hooks.py:260] loss = 0.60676545, step = 2300 (78.142 sec)\n","INFO:tensorflow:global_step/sec: 1.27968\n","I0617 09:46:56.075233 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27968\n","INFO:tensorflow:loss = 0.641906, step = 2400 (78.145 sec)\n","I0617 09:46:56.076241 140626870351744 basic_session_run_hooks.py:260] loss = 0.641906, step = 2400 (78.145 sec)\n","INFO:tensorflow:global_step/sec: 1.28074\n","I0617 09:48:14.155119 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28074\n","INFO:tensorflow:loss = 0.6851827, step = 2500 (78.080 sec)\n","I0617 09:48:14.156183 140626870351744 basic_session_run_hooks.py:260] loss = 0.6851827, step = 2500 (78.080 sec)\n","INFO:tensorflow:global_step/sec: 1.28008\n","I0617 09:49:32.275528 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28008\n","INFO:tensorflow:loss = 0.41374606, step = 2600 (78.120 sec)\n","I0617 09:49:32.276667 140626870351744 basic_session_run_hooks.py:260] loss = 0.41374606, step = 2600 (78.120 sec)\n","INFO:tensorflow:Saving checkpoints for 2665 into training/model.ckpt.\n","I0617 09:50:22.164527 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 2665 into training/model.ckpt.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0617 09:50:23.534569 140626870351744 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe26c4d90d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 09:50:25.864950 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe26c4d90d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 09:50:26.298575 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:50:26.324813 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:50:29.084936 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:50:29.097719 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 09:50:29.098061 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:50:29.540470 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 09:50:29.797441 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 09:50:31.547474 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T09:50:31Z\n","I0617 09:50:31.566509 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T09:50:31Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 09:50:32.219486 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 09:50:32.220193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:50:32.220496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 09:50:32.220599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 09:50:32.220631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 09:50:32.220654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 09:50:32.220681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 09:50:32.220703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 09:50:32.220723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 09:50:32.220743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 09:50:32.220855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:50:32.221186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:50:32.221404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 09:50:32.221488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 09:50:32.221503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 09:50:32.221511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 09:50:32.221651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:50:32.221981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 09:50:32.222213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-2665\n","I0617 09:50:32.223447 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-2665\n","INFO:tensorflow:Running local_init_op.\n","I0617 09:50:33.810696 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 09:50:33.996209 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 09:53:45.822856 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.38s)\n","I0617 09:53:46.203857 140623412950784 coco_tools.py:131] DONE (t=0.38s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.84s).\n","Accumulating evaluation results...\n","DONE (t=2.47s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.509\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.546\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n","INFO:tensorflow:Finished evaluation at 2020-06-17-09:54:06\n","I0617 09:54:06.279713 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-09:54:06\n","INFO:tensorflow:Saving dict for global step 2665: DetectionBoxes_Precision/mAP = 0.35454267, DetectionBoxes_Precision/mAP (large) = 0.017795753, DetectionBoxes_Precision/mAP (medium) = 0.30537555, DetectionBoxes_Precision/mAP (small) = 0.3638684, DetectionBoxes_Precision/mAP@.50IOU = 0.733447, DetectionBoxes_Precision/mAP@.75IOU = 0.27683026, DetectionBoxes_Recall/AR@1 = 0.27227283, DetectionBoxes_Recall/AR@10 = 0.5094313, DetectionBoxes_Recall/AR@100 = 0.5523578, DetectionBoxes_Recall/AR@100 (large) = 0.64666665, DetectionBoxes_Recall/AR@100 (medium) = 0.59180576, DetectionBoxes_Recall/AR@100 (small) = 0.5459232, Loss/BoxClassifierLoss/classification_loss = 0.16357653, Loss/BoxClassifierLoss/localization_loss = 0.13031381, Loss/RPNLoss/localization_loss = 0.029621221, Loss/RPNLoss/objectness_loss = 0.04932744, Loss/total_loss = 0.3728393, global_step = 2665, learning_rate = 0.0003, loss = 0.3728393\n","I0617 09:54:06.280013 140626870351744 estimator.py:2049] Saving dict for global step 2665: DetectionBoxes_Precision/mAP = 0.35454267, DetectionBoxes_Precision/mAP (large) = 0.017795753, DetectionBoxes_Precision/mAP (medium) = 0.30537555, DetectionBoxes_Precision/mAP (small) = 0.3638684, DetectionBoxes_Precision/mAP@.50IOU = 0.733447, DetectionBoxes_Precision/mAP@.75IOU = 0.27683026, DetectionBoxes_Recall/AR@1 = 0.27227283, DetectionBoxes_Recall/AR@10 = 0.5094313, DetectionBoxes_Recall/AR@100 = 0.5523578, DetectionBoxes_Recall/AR@100 (large) = 0.64666665, DetectionBoxes_Recall/AR@100 (medium) = 0.59180576, DetectionBoxes_Recall/AR@100 (small) = 0.5459232, Loss/BoxClassifierLoss/classification_loss = 0.16357653, Loss/BoxClassifierLoss/localization_loss = 0.13031381, Loss/RPNLoss/localization_loss = 0.029621221, Loss/RPNLoss/objectness_loss = 0.04932744, Loss/total_loss = 0.3728393, global_step = 2665, learning_rate = 0.0003, loss = 0.3728393\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2665: training/model.ckpt-2665\n","I0617 09:54:06.280923 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2665: training/model.ckpt-2665\n","INFO:tensorflow:global_step/sec: 0.330943\n","I0617 09:54:34.442787 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.330943\n","INFO:tensorflow:loss = 0.5714846, step = 2700 (302.167 sec)\n","I0617 09:54:34.444084 140626870351744 basic_session_run_hooks.py:260] loss = 0.5714846, step = 2700 (302.167 sec)\n","INFO:tensorflow:global_step/sec: 1.28397\n","I0617 09:55:52.325942 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28397\n","INFO:tensorflow:loss = 0.67150706, step = 2800 (77.883 sec)\n","I0617 09:55:52.327135 140626870351744 basic_session_run_hooks.py:260] loss = 0.67150706, step = 2800 (77.883 sec)\n","INFO:tensorflow:global_step/sec: 1.2833\n","I0617 09:57:10.250084 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.2833\n","INFO:tensorflow:loss = 0.5609437, step = 2900 (77.924 sec)\n","I0617 09:57:10.251349 140626870351744 basic_session_run_hooks.py:260] loss = 0.5609437, step = 2900 (77.924 sec)\n","INFO:tensorflow:global_step/sec: 1.2776\n","I0617 09:58:28.521588 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.2776\n","INFO:tensorflow:loss = 0.6144182, step = 3000 (78.271 sec)\n","I0617 09:58:28.522636 140626870351744 basic_session_run_hooks.py:260] loss = 0.6144182, step = 3000 (78.271 sec)\n","INFO:tensorflow:global_step/sec: 1.28354\n","I0617 09:59:46.431192 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28354\n","INFO:tensorflow:loss = 0.56862134, step = 3100 (77.910 sec)\n","I0617 09:59:46.432426 140626870351744 basic_session_run_hooks.py:260] loss = 0.56862134, step = 3100 (77.910 sec)\n","INFO:tensorflow:Saving checkpoints for 3147 into training/model.ckpt.\n","I0617 10:00:22.338126 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 3147 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe277b8d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 10:00:26.053051 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe277b8d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 10:00:26.477441 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:00:26.503793 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:00:29.624325 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:00:29.636837 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 10:00:29.637178 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:00:30.079743 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:00:30.332455 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 10:00:32.130332 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T10:00:32Z\n","I0617 10:00:32.145547 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T10:00:32Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 10:00:32.796365 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 10:00:32.797106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:00:32.797396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 10:00:32.797491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 10:00:32.797516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 10:00:32.797539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 10:00:32.797561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 10:00:32.797587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 10:00:32.797607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 10:00:32.797627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 10:00:32.797741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:00:32.798095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:00:32.798326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 10:00:32.798370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 10:00:32.798384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 10:00:32.798393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 10:00:32.798525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:00:32.798823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:00:32.799062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-3147\n","I0617 10:00:32.800132 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-3147\n","INFO:tensorflow:Running local_init_op.\n","I0617 10:00:34.455596 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 10:00:34.650031 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 10:03:45.577576 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.41s)\n","I0617 10:03:45.988713 140623412950784 coco_tools.py:131] DONE (t=0.41s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.81s).\n","Accumulating evaluation results...\n","DONE (t=2.52s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.734\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.273\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.545\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n","INFO:tensorflow:Finished evaluation at 2020-06-17-10:04:06\n","I0617 10:04:06.074697 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-10:04:06\n","INFO:tensorflow:Saving dict for global step 3147: DetectionBoxes_Precision/mAP = 0.3537408, DetectionBoxes_Precision/mAP (large) = 0.011778688, DetectionBoxes_Precision/mAP (medium) = 0.30830944, DetectionBoxes_Precision/mAP (small) = 0.36135313, DetectionBoxes_Precision/mAP@.50IOU = 0.734487, DetectionBoxes_Precision/mAP@.75IOU = 0.28439647, DetectionBoxes_Recall/AR@1 = 0.27308238, DetectionBoxes_Recall/AR@10 = 0.51036227, DetectionBoxes_Recall/AR@100 = 0.5526007, DetectionBoxes_Recall/AR@100 (large) = 0.68, DetectionBoxes_Recall/AR@100 (medium) = 0.5996965, DetectionBoxes_Recall/AR@100 (small) = 0.5448922, Loss/BoxClassifierLoss/classification_loss = 0.16500027, Loss/BoxClassifierLoss/localization_loss = 0.12706405, Loss/RPNLoss/localization_loss = 0.029571334, Loss/RPNLoss/objectness_loss = 0.048917245, Loss/total_loss = 0.37055334, global_step = 3147, learning_rate = 0.0003, loss = 0.37055334\n","I0617 10:04:06.074999 140626870351744 estimator.py:2049] Saving dict for global step 3147: DetectionBoxes_Precision/mAP = 0.3537408, DetectionBoxes_Precision/mAP (large) = 0.011778688, DetectionBoxes_Precision/mAP (medium) = 0.30830944, DetectionBoxes_Precision/mAP (small) = 0.36135313, DetectionBoxes_Precision/mAP@.50IOU = 0.734487, DetectionBoxes_Precision/mAP@.75IOU = 0.28439647, DetectionBoxes_Recall/AR@1 = 0.27308238, DetectionBoxes_Recall/AR@10 = 0.51036227, DetectionBoxes_Recall/AR@100 = 0.5526007, DetectionBoxes_Recall/AR@100 (large) = 0.68, DetectionBoxes_Recall/AR@100 (medium) = 0.5996965, DetectionBoxes_Recall/AR@100 (small) = 0.5448922, Loss/BoxClassifierLoss/classification_loss = 0.16500027, Loss/BoxClassifierLoss/localization_loss = 0.12706405, Loss/RPNLoss/localization_loss = 0.029571334, Loss/RPNLoss/objectness_loss = 0.048917245, Loss/total_loss = 0.37055334, global_step = 3147, learning_rate = 0.0003, loss = 0.37055334\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3147: training/model.ckpt-3147\n","I0617 10:04:06.075951 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3147: training/model.ckpt-3147\n","INFO:tensorflow:global_step/sec: 0.331294\n","I0617 10:04:48.278002 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.331294\n","INFO:tensorflow:loss = 0.61747855, step = 3200 (301.847 sec)\n","I0617 10:04:48.279203 140626870351744 basic_session_run_hooks.py:260] loss = 0.61747855, step = 3200 (301.847 sec)\n","INFO:tensorflow:global_step/sec: 1.27739\n","I0617 10:06:06.562511 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27739\n","INFO:tensorflow:loss = 0.5374551, step = 3300 (78.284 sec)\n","I0617 10:06:06.563679 140626870351744 basic_session_run_hooks.py:260] loss = 0.5374551, step = 3300 (78.284 sec)\n","INFO:tensorflow:global_step/sec: 1.28219\n","I0617 10:07:24.553790 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28219\n","INFO:tensorflow:loss = 0.56191707, step = 3400 (77.991 sec)\n","I0617 10:07:24.555084 140626870351744 basic_session_run_hooks.py:260] loss = 0.56191707, step = 3400 (77.991 sec)\n","INFO:tensorflow:global_step/sec: 1.28136\n","I0617 10:08:42.595657 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28136\n","INFO:tensorflow:loss = 0.49502504, step = 3500 (78.042 sec)\n","I0617 10:08:42.596651 140626870351744 basic_session_run_hooks.py:260] loss = 0.49502504, step = 3500 (78.042 sec)\n","INFO:tensorflow:global_step/sec: 1.27936\n","I0617 10:10:00.759872 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27936\n","INFO:tensorflow:loss = 0.53125226, step = 3600 (78.165 sec)\n","I0617 10:10:00.761362 140626870351744 basic_session_run_hooks.py:260] loss = 0.53125226, step = 3600 (78.165 sec)\n","INFO:tensorflow:Saving checkpoints for 3629 into training/model.ckpt.\n","I0617 10:10:22.562315 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 3629 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe26ab708c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 10:10:26.255181 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe26ab708c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 10:10:26.678377 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:10:26.705323 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:10:29.449012 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:10:29.461740 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 10:10:29.462078 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:10:29.904796 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:10:30.162547 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 10:10:31.939446 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T10:10:31Z\n","I0617 10:10:31.954478 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T10:10:31Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 10:10:32.598667 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 10:10:32.599411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:10:32.599721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 10:10:32.599812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 10:10:32.599837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 10:10:32.599859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 10:10:32.599882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 10:10:32.599916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 10:10:32.599938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 10:10:32.599960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 10:10:32.600069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:10:32.600370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:10:32.600584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 10:10:32.600664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 10:10:32.600678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 10:10:32.600687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 10:10:32.600825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:10:32.601145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:10:32.601417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-3629\n","I0617 10:10:32.602469 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-3629\n","INFO:tensorflow:Running local_init_op.\n","I0617 10:10:34.208880 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 10:10:34.396227 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 10:13:47.877571 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.39s)\n","I0617 10:13:48.270335 140623412950784 coco_tools.py:131] DONE (t=0.39s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.86s).\n","Accumulating evaluation results...\n","DONE (t=2.50s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.366\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.273\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.538\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n","INFO:tensorflow:Finished evaluation at 2020-06-17-10:14:08\n","I0617 10:14:08.428132 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-10:14:08\n","INFO:tensorflow:Saving dict for global step 3629: DetectionBoxes_Precision/mAP = 0.35865676, DetectionBoxes_Precision/mAP (large) = 0.023248209, DetectionBoxes_Precision/mAP (medium) = 0.30749446, DetectionBoxes_Precision/mAP (small) = 0.36647624, DetectionBoxes_Precision/mAP@.50IOU = 0.7485957, DetectionBoxes_Precision/mAP@.75IOU = 0.2722362, DetectionBoxes_Recall/AR@1 = 0.27296093, DetectionBoxes_Recall/AR@10 = 0.5058895, DetectionBoxes_Recall/AR@100 = 0.54669094, DetectionBoxes_Recall/AR@100 (large) = 0.6333333, DetectionBoxes_Recall/AR@100 (medium) = 0.59817904, DetectionBoxes_Recall/AR@100 (small) = 0.5384255, Loss/BoxClassifierLoss/classification_loss = 0.15685257, Loss/BoxClassifierLoss/localization_loss = 0.13080662, Loss/RPNLoss/localization_loss = 0.028862972, Loss/RPNLoss/objectness_loss = 0.046564173, Loss/total_loss = 0.3630861, global_step = 3629, learning_rate = 0.0003, loss = 0.3630861\n","I0617 10:14:08.428433 140626870351744 estimator.py:2049] Saving dict for global step 3629: DetectionBoxes_Precision/mAP = 0.35865676, DetectionBoxes_Precision/mAP (large) = 0.023248209, DetectionBoxes_Precision/mAP (medium) = 0.30749446, DetectionBoxes_Precision/mAP (small) = 0.36647624, DetectionBoxes_Precision/mAP@.50IOU = 0.7485957, DetectionBoxes_Precision/mAP@.75IOU = 0.2722362, DetectionBoxes_Recall/AR@1 = 0.27296093, DetectionBoxes_Recall/AR@10 = 0.5058895, DetectionBoxes_Recall/AR@100 = 0.54669094, DetectionBoxes_Recall/AR@100 (large) = 0.6333333, DetectionBoxes_Recall/AR@100 (medium) = 0.59817904, DetectionBoxes_Recall/AR@100 (small) = 0.5384255, Loss/BoxClassifierLoss/classification_loss = 0.15685257, Loss/BoxClassifierLoss/localization_loss = 0.13080662, Loss/RPNLoss/localization_loss = 0.028862972, Loss/RPNLoss/objectness_loss = 0.046564173, Loss/total_loss = 0.3630861, global_step = 3629, learning_rate = 0.0003, loss = 0.3630861\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3629: training/model.ckpt-3629\n","I0617 10:14:08.429383 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3629: training/model.ckpt-3629\n","INFO:tensorflow:global_step/sec: 0.328863\n","I0617 10:15:04.837471 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.328863\n","INFO:tensorflow:loss = 0.6161774, step = 3700 (304.077 sec)\n","I0617 10:15:04.838436 140626870351744 basic_session_run_hooks.py:260] loss = 0.6161774, step = 3700 (304.077 sec)\n","INFO:tensorflow:global_step/sec: 1.27882\n","I0617 10:16:23.034434 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27882\n","INFO:tensorflow:loss = 0.49155244, step = 3800 (78.197 sec)\n","I0617 10:16:23.035412 140626870351744 basic_session_run_hooks.py:260] loss = 0.49155244, step = 3800 (78.197 sec)\n","INFO:tensorflow:global_step/sec: 1.2786\n","I0617 10:17:41.245131 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.2786\n","INFO:tensorflow:loss = 0.73171675, step = 3900 (78.211 sec)\n","I0617 10:17:41.246343 140626870351744 basic_session_run_hooks.py:260] loss = 0.73171675, step = 3900 (78.211 sec)\n","INFO:tensorflow:global_step/sec: 1.27776\n","I0617 10:18:59.506954 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27776\n","INFO:tensorflow:loss = 0.9302973, step = 4000 (78.262 sec)\n","I0617 10:18:59.508074 140626870351744 basic_session_run_hooks.py:260] loss = 0.9302973, step = 4000 (78.262 sec)\n","INFO:tensorflow:global_step/sec: 1.27948\n","I0617 10:20:17.664002 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27948\n","INFO:tensorflow:loss = 0.6789362, step = 4100 (78.157 sec)\n","I0617 10:20:17.665114 140626870351744 basic_session_run_hooks.py:260] loss = 0.6789362, step = 4100 (78.157 sec)\n","INFO:tensorflow:Saving checkpoints for 4108 into training/model.ckpt.\n","I0617 10:20:23.124977 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 4108 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe26ab700d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 10:20:26.877270 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe26ab700d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 10:20:27.303912 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:20:27.330389 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:20:30.077683 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:20:30.090431 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 10:20:30.090771 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:20:30.531064 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:20:30.797829 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 10:20:32.558160 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T10:20:32Z\n","I0617 10:20:32.572999 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T10:20:32Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 10:20:33.220927 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 10:20:33.221646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:20:33.222047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 10:20:33.222160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 10:20:33.222198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 10:20:33.222223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 10:20:33.222243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 10:20:33.222262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 10:20:33.222281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 10:20:33.222301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 10:20:33.222412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:20:33.222734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:20:33.222970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 10:20:33.223015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 10:20:33.223028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 10:20:33.223037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 10:20:33.223164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:20:33.223462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:20:33.223694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-4108\n","I0617 10:20:33.224827 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-4108\n","INFO:tensorflow:Running local_init_op.\n","I0617 10:20:34.833998 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 10:20:35.022238 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 10:23:46.675792 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.40s)\n","I0617 10:23:47.072021 140623412950784 coco_tools.py:131] DONE (t=0.40s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.78s).\n","Accumulating evaluation results...\n","DONE (t=2.50s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.380\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.520\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.552\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n","INFO:tensorflow:Finished evaluation at 2020-06-17-10:24:07\n","I0617 10:24:07.125383 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-10:24:07\n","INFO:tensorflow:Saving dict for global step 4108: DetectionBoxes_Precision/mAP = 0.3700234, DetectionBoxes_Precision/mAP (large) = 0.030702423, DetectionBoxes_Precision/mAP (medium) = 0.3162931, DetectionBoxes_Precision/mAP (small) = 0.37966132, DetectionBoxes_Precision/mAP@.50IOU = 0.75278336, DetectionBoxes_Precision/mAP@.75IOU = 0.30342102, DetectionBoxes_Recall/AR@1 = 0.2791945, DetectionBoxes_Recall/AR@10 = 0.5203805, DetectionBoxes_Recall/AR@100 = 0.5591783, DetectionBoxes_Recall/AR@100 (large) = 0.6933333, DetectionBoxes_Recall/AR@100 (medium) = 0.600607, DetectionBoxes_Recall/AR@100 (small) = 0.5523196, Loss/BoxClassifierLoss/classification_loss = 0.15474711, Loss/BoxClassifierLoss/localization_loss = 0.12742703, Loss/RPNLoss/localization_loss = 0.02939345, Loss/RPNLoss/objectness_loss = 0.048543077, Loss/total_loss = 0.36011076, global_step = 4108, learning_rate = 0.0003, loss = 0.36011076\n","I0617 10:24:07.125662 140626870351744 estimator.py:2049] Saving dict for global step 4108: DetectionBoxes_Precision/mAP = 0.3700234, DetectionBoxes_Precision/mAP (large) = 0.030702423, DetectionBoxes_Precision/mAP (medium) = 0.3162931, DetectionBoxes_Precision/mAP (small) = 0.37966132, DetectionBoxes_Precision/mAP@.50IOU = 0.75278336, DetectionBoxes_Precision/mAP@.75IOU = 0.30342102, DetectionBoxes_Recall/AR@1 = 0.2791945, DetectionBoxes_Recall/AR@10 = 0.5203805, DetectionBoxes_Recall/AR@100 = 0.5591783, DetectionBoxes_Recall/AR@100 (large) = 0.6933333, DetectionBoxes_Recall/AR@100 (medium) = 0.600607, DetectionBoxes_Recall/AR@100 (small) = 0.5523196, Loss/BoxClassifierLoss/classification_loss = 0.15474711, Loss/BoxClassifierLoss/localization_loss = 0.12742703, Loss/RPNLoss/localization_loss = 0.02939345, Loss/RPNLoss/objectness_loss = 0.048543077, Loss/total_loss = 0.36011076, global_step = 4108, learning_rate = 0.0003, loss = 0.36011076\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4108: training/model.ckpt-4108\n","I0617 10:24:07.126700 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4108: training/model.ckpt-4108\n","INFO:tensorflow:global_step/sec: 0.330912\n","I0617 10:25:19.859094 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.330912\n","INFO:tensorflow:loss = 0.6541584, step = 4200 (302.195 sec)\n","I0617 10:25:19.860203 140626870351744 basic_session_run_hooks.py:260] loss = 0.6541584, step = 4200 (302.195 sec)\n","INFO:tensorflow:global_step/sec: 1.282\n","I0617 10:26:37.861953 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.282\n","INFO:tensorflow:loss = 0.5348252, step = 4300 (78.003 sec)\n","I0617 10:26:37.863142 140626870351744 basic_session_run_hooks.py:260] loss = 0.5348252, step = 4300 (78.003 sec)\n","INFO:tensorflow:global_step/sec: 1.27723\n","I0617 10:27:56.156102 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27723\n","INFO:tensorflow:loss = 0.3457889, step = 4400 (78.294 sec)\n","I0617 10:27:56.157269 140626870351744 basic_session_run_hooks.py:260] loss = 0.3457889, step = 4400 (78.294 sec)\n","INFO:tensorflow:global_step/sec: 1.28118\n","I0617 10:29:14.208870 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28118\n","INFO:tensorflow:loss = 0.4076098, step = 4500 (78.053 sec)\n","I0617 10:29:14.209923 140626870351744 basic_session_run_hooks.py:260] loss = 0.4076098, step = 4500 (78.053 sec)\n","INFO:tensorflow:Saving checkpoints for 4590 into training/model.ckpt.\n","I0617 10:30:23.713011 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 4590 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe26bfa22f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 10:30:27.452865 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe26bfa22f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 10:30:27.885601 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:30:27.912102 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:30:30.652158 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:30:30.664421 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 10:30:30.664748 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:30:31.111496 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:30:31.370558 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 10:30:33.134457 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T10:30:33Z\n","I0617 10:30:33.149610 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T10:30:33Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 10:30:33.797358 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 10:30:33.798072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:30:33.798377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 10:30:33.798488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 10:30:33.798513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 10:30:33.798536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 10:30:33.798558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 10:30:33.798586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 10:30:33.798613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 10:30:33.798633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 10:30:33.798747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:30:33.799131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:30:33.799343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 10:30:33.799437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 10:30:33.799451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 10:30:33.799460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 10:30:33.799589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:30:33.799889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:30:33.800142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-4590\n","I0617 10:30:33.801277 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-4590\n","INFO:tensorflow:Running local_init_op.\n","I0617 10:30:35.429614 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 10:30:35.614787 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 10:33:46.699657 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.39s)\n","I0617 10:33:47.091320 140623412950784 coco_tools.py:131] DONE (t=0.39s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.83s).\n","Accumulating evaluation results...\n","DONE (t=2.48s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.374\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.278\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.520\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.552\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n","INFO:tensorflow:Finished evaluation at 2020-06-17-10:34:07\n","I0617 10:34:07.166863 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-10:34:07\n","INFO:tensorflow:Saving dict for global step 4590: DetectionBoxes_Precision/mAP = 0.36588943, DetectionBoxes_Precision/mAP (large) = 0.02467807, DetectionBoxes_Precision/mAP (medium) = 0.31734407, DetectionBoxes_Precision/mAP (small) = 0.37371987, DetectionBoxes_Precision/mAP@.50IOU = 0.75083137, DetectionBoxes_Precision/mAP@.75IOU = 0.29280156, DetectionBoxes_Recall/AR@1 = 0.2781016, DetectionBoxes_Recall/AR@10 = 0.51969236, DetectionBoxes_Recall/AR@100 = 0.55883425, DetectionBoxes_Recall/AR@100 (large) = 0.66, DetectionBoxes_Recall/AR@100 (medium) = 0.6003035, DetectionBoxes_Recall/AR@100 (small) = 0.5520853, Loss/BoxClassifierLoss/classification_loss = 0.1614168, Loss/BoxClassifierLoss/localization_loss = 0.12654638, Loss/RPNLoss/localization_loss = 0.028816273, Loss/RPNLoss/objectness_loss = 0.047004834, Loss/total_loss = 0.36378407, global_step = 4590, learning_rate = 0.0003, loss = 0.36378407\n","I0617 10:34:07.167186 140626870351744 estimator.py:2049] Saving dict for global step 4590: DetectionBoxes_Precision/mAP = 0.36588943, DetectionBoxes_Precision/mAP (large) = 0.02467807, DetectionBoxes_Precision/mAP (medium) = 0.31734407, DetectionBoxes_Precision/mAP (small) = 0.37371987, DetectionBoxes_Precision/mAP@.50IOU = 0.75083137, DetectionBoxes_Precision/mAP@.75IOU = 0.29280156, DetectionBoxes_Recall/AR@1 = 0.2781016, DetectionBoxes_Recall/AR@10 = 0.51969236, DetectionBoxes_Recall/AR@100 = 0.55883425, DetectionBoxes_Recall/AR@100 (large) = 0.66, DetectionBoxes_Recall/AR@100 (medium) = 0.6003035, DetectionBoxes_Recall/AR@100 (small) = 0.5520853, Loss/BoxClassifierLoss/classification_loss = 0.1614168, Loss/BoxClassifierLoss/localization_loss = 0.12654638, Loss/RPNLoss/localization_loss = 0.028816273, Loss/RPNLoss/objectness_loss = 0.047004834, Loss/total_loss = 0.36378407, global_step = 4590, learning_rate = 0.0003, loss = 0.36378407\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4590: training/model.ckpt-4590\n","I0617 10:34:07.168081 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4590: training/model.ckpt-4590\n","INFO:tensorflow:global_step/sec: 0.331629\n","I0617 10:34:15.750813 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.331629\n","INFO:tensorflow:loss = 0.7082207, step = 4600 (301.542 sec)\n","I0617 10:34:15.751995 140626870351744 basic_session_run_hooks.py:260] loss = 0.7082207, step = 4600 (301.542 sec)\n","INFO:tensorflow:global_step/sec: 1.27843\n","I0617 10:35:33.972025 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27843\n","INFO:tensorflow:loss = 0.5735248, step = 4700 (78.221 sec)\n","I0617 10:35:33.972986 140626870351744 basic_session_run_hooks.py:260] loss = 0.5735248, step = 4700 (78.221 sec)\n","INFO:tensorflow:global_step/sec: 1.28212\n","I0617 10:36:51.967699 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28212\n","INFO:tensorflow:loss = 0.42972475, step = 4800 (77.996 sec)\n","I0617 10:36:51.968835 140626870351744 basic_session_run_hooks.py:260] loss = 0.42972475, step = 4800 (77.996 sec)\n","INFO:tensorflow:global_step/sec: 1.28166\n","I0617 10:38:09.991439 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28166\n","INFO:tensorflow:loss = 0.67952955, step = 4900 (78.024 sec)\n","I0617 10:38:09.992465 140626870351744 basic_session_run_hooks.py:260] loss = 0.67952955, step = 4900 (78.024 sec)\n","INFO:tensorflow:global_step/sec: 1.2836\n","I0617 10:39:27.897501 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.2836\n","INFO:tensorflow:loss = 0.83128893, step = 5000 (77.906 sec)\n","I0617 10:39:27.898498 140626870351744 basic_session_run_hooks.py:260] loss = 0.83128893, step = 5000 (77.906 sec)\n","INFO:tensorflow:Saving checkpoints for 5073 into training/model.ckpt.\n","I0617 10:40:24.179537 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 5073 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe278c06158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 10:40:27.863570 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe278c06158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 10:40:28.299134 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:40:28.324838 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:40:31.056787 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:40:31.068925 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 10:40:31.069242 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:40:31.507144 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:40:31.761714 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 10:40:33.513671 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T10:40:33Z\n","I0617 10:40:33.529868 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T10:40:33Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 10:40:34.194325 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 10:40:34.195068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:40:34.195404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 10:40:34.195504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 10:40:34.195529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 10:40:34.195551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 10:40:34.195572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 10:40:34.195593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 10:40:34.195616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 10:40:34.195639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 10:40:34.195747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:40:34.196175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:40:34.196407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 10:40:34.196447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 10:40:34.196460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 10:40:34.196468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 10:40:34.196587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:40:34.196943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:40:34.197201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-5073\n","I0617 10:40:34.198258 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-5073\n","INFO:tensorflow:Running local_init_op.\n","I0617 10:40:35.824695 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 10:40:36.010998 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 10:43:47.224718 140623421343488 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.40s)\n","I0617 10:43:47.625650 140623421343488 coco_tools.py:131] DONE (t=0.40s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=17.18s).\n","Accumulating evaluation results...\n","DONE (t=2.46s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.051\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.561\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n","INFO:tensorflow:Finished evaluation at 2020-06-17-10:44:08\n","I0617 10:44:08.006761 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-10:44:08\n","INFO:tensorflow:Saving dict for global step 5073: DetectionBoxes_Precision/mAP = 0.3775027, DetectionBoxes_Precision/mAP (large) = 0.050679274, DetectionBoxes_Precision/mAP (medium) = 0.32801136, DetectionBoxes_Precision/mAP (small) = 0.38512984, DetectionBoxes_Precision/mAP@.50IOU = 0.7562433, DetectionBoxes_Precision/mAP@.75IOU = 0.3196513, DetectionBoxes_Recall/AR@1 = 0.28053024, DetectionBoxes_Recall/AR@10 = 0.53141063, DetectionBoxes_Recall/AR@100 = 0.5691965, DetectionBoxes_Recall/AR@100 (large) = 0.64666665, DetectionBoxes_Recall/AR@100 (medium) = 0.62139606, DetectionBoxes_Recall/AR@100 (small) = 0.5608482, Loss/BoxClassifierLoss/classification_loss = 0.15752065, Loss/BoxClassifierLoss/localization_loss = 0.12370388, Loss/RPNLoss/localization_loss = 0.028634785, Loss/RPNLoss/objectness_loss = 0.047720816, Loss/total_loss = 0.3575807, global_step = 5073, learning_rate = 0.0003, loss = 0.3575807\n","I0617 10:44:08.007064 140626870351744 estimator.py:2049] Saving dict for global step 5073: DetectionBoxes_Precision/mAP = 0.3775027, DetectionBoxes_Precision/mAP (large) = 0.050679274, DetectionBoxes_Precision/mAP (medium) = 0.32801136, DetectionBoxes_Precision/mAP (small) = 0.38512984, DetectionBoxes_Precision/mAP@.50IOU = 0.7562433, DetectionBoxes_Precision/mAP@.75IOU = 0.3196513, DetectionBoxes_Recall/AR@1 = 0.28053024, DetectionBoxes_Recall/AR@10 = 0.53141063, DetectionBoxes_Recall/AR@100 = 0.5691965, DetectionBoxes_Recall/AR@100 (large) = 0.64666665, DetectionBoxes_Recall/AR@100 (medium) = 0.62139606, DetectionBoxes_Recall/AR@100 (small) = 0.5608482, Loss/BoxClassifierLoss/classification_loss = 0.15752065, Loss/BoxClassifierLoss/localization_loss = 0.12370388, Loss/RPNLoss/localization_loss = 0.028634785, Loss/RPNLoss/objectness_loss = 0.047720816, Loss/total_loss = 0.3575807, global_step = 5073, learning_rate = 0.0003, loss = 0.3575807\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5073: training/model.ckpt-5073\n","I0617 10:44:08.007982 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5073: training/model.ckpt-5073\n","INFO:tensorflow:global_step/sec: 0.331098\n","I0617 10:44:29.922966 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.331098\n","INFO:tensorflow:loss = 0.3686535, step = 5100 (302.025 sec)\n","I0617 10:44:29.923841 140626870351744 basic_session_run_hooks.py:260] loss = 0.3686535, step = 5100 (302.025 sec)\n","INFO:tensorflow:global_step/sec: 1.28241\n","I0617 10:45:47.901190 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28241\n","INFO:tensorflow:loss = 0.6603526, step = 5200 (77.978 sec)\n","I0617 10:45:47.902219 140626870351744 basic_session_run_hooks.py:260] loss = 0.6603526, step = 5200 (77.978 sec)\n","INFO:tensorflow:global_step/sec: 1.28096\n","I0617 10:47:05.967815 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28096\n","INFO:tensorflow:loss = 0.5303992, step = 5300 (78.067 sec)\n","I0617 10:47:05.969085 140626870351744 basic_session_run_hooks.py:260] loss = 0.5303992, step = 5300 (78.067 sec)\n","INFO:tensorflow:global_step/sec: 1.28065\n","I0617 10:48:24.053293 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28065\n","INFO:tensorflow:loss = 0.6947307, step = 5400 (78.085 sec)\n","I0617 10:48:24.054181 140626870351744 basic_session_run_hooks.py:260] loss = 0.6947307, step = 5400 (78.085 sec)\n","INFO:tensorflow:global_step/sec: 1.27622\n","I0617 10:49:42.409462 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27622\n","INFO:tensorflow:loss = 0.8008859, step = 5500 (78.357 sec)\n","I0617 10:49:42.410718 140626870351744 basic_session_run_hooks.py:260] loss = 0.8008859, step = 5500 (78.357 sec)\n","INFO:tensorflow:Saving checkpoints for 5555 into training/model.ckpt.\n","I0617 10:50:24.458422 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 5555 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe287d240d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 10:50:28.140138 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe287d240d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 10:50:28.566371 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:50:28.592549 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:50:31.344924 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:50:31.357505 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 10:50:31.357836 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:50:31.791820 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 10:50:32.041673 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 10:50:33.802592 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T10:50:33Z\n","I0617 10:50:33.817805 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T10:50:33Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 10:50:34.462670 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 10:50:34.463378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:50:34.463665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 10:50:34.463753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 10:50:34.463777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 10:50:34.463800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 10:50:34.463821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 10:50:34.463842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 10:50:34.463867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 10:50:34.463888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 10:50:34.464025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:50:34.464364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:50:34.464595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 10:50:34.464682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 10:50:34.464700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 10:50:34.464709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 10:50:34.464841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:50:34.465163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 10:50:34.465405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-5555\n","I0617 10:50:34.466624 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-5555\n","INFO:tensorflow:Running local_init_op.\n","I0617 10:50:36.083552 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 10:50:36.289159 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 10:53:47.699677 140623421343488 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.42s)\n","I0617 10:53:48.120084 140623421343488 coco_tools.py:131] DONE (t=0.42s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.61s).\n","Accumulating evaluation results...\n","DONE (t=2.44s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.553\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n","INFO:tensorflow:Finished evaluation at 2020-06-17-10:54:07\n","I0617 10:54:07.912842 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-10:54:07\n","INFO:tensorflow:Saving dict for global step 5555: DetectionBoxes_Precision/mAP = 0.36846098, DetectionBoxes_Precision/mAP (large) = 0.04111025, DetectionBoxes_Precision/mAP (medium) = 0.31309694, DetectionBoxes_Precision/mAP (small) = 0.3770236, DetectionBoxes_Precision/mAP@.50IOU = 0.75070286, DetectionBoxes_Precision/mAP@.75IOU = 0.29450706, DetectionBoxes_Recall/AR@1 = 0.27907306, DetectionBoxes_Recall/AR@10 = 0.52206033, DetectionBoxes_Recall/AR@100 = 0.5595021, DetectionBoxes_Recall/AR@100 (large) = 0.62, DetectionBoxes_Recall/AR@100 (medium) = 0.5980273, DetectionBoxes_Recall/AR@100 (small) = 0.5533271, Loss/BoxClassifierLoss/classification_loss = 0.1670357, Loss/BoxClassifierLoss/localization_loss = 0.12627587, Loss/RPNLoss/localization_loss = 0.029111363, Loss/RPNLoss/objectness_loss = 0.05003918, Loss/total_loss = 0.37246218, global_step = 5555, learning_rate = 0.0003, loss = 0.37246218\n","I0617 10:54:07.913162 140626870351744 estimator.py:2049] Saving dict for global step 5555: DetectionBoxes_Precision/mAP = 0.36846098, DetectionBoxes_Precision/mAP (large) = 0.04111025, DetectionBoxes_Precision/mAP (medium) = 0.31309694, DetectionBoxes_Precision/mAP (small) = 0.3770236, DetectionBoxes_Precision/mAP@.50IOU = 0.75070286, DetectionBoxes_Precision/mAP@.75IOU = 0.29450706, DetectionBoxes_Recall/AR@1 = 0.27907306, DetectionBoxes_Recall/AR@10 = 0.52206033, DetectionBoxes_Recall/AR@100 = 0.5595021, DetectionBoxes_Recall/AR@100 (large) = 0.62, DetectionBoxes_Recall/AR@100 (medium) = 0.5980273, DetectionBoxes_Recall/AR@100 (small) = 0.5533271, Loss/BoxClassifierLoss/classification_loss = 0.1670357, Loss/BoxClassifierLoss/localization_loss = 0.12627587, Loss/RPNLoss/localization_loss = 0.029111363, Loss/RPNLoss/objectness_loss = 0.05003918, Loss/total_loss = 0.37246218, global_step = 5555, learning_rate = 0.0003, loss = 0.37246218\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5555: training/model.ckpt-5555\n","I0617 10:54:07.914063 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5555: training/model.ckpt-5555\n","INFO:tensorflow:global_step/sec: 0.331604\n","I0617 10:54:43.974407 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.331604\n","INFO:tensorflow:loss = 0.53352386, step = 5600 (301.565 sec)\n","I0617 10:54:43.975546 140626870351744 basic_session_run_hooks.py:260] loss = 0.53352386, step = 5600 (301.565 sec)\n","INFO:tensorflow:global_step/sec: 1.28045\n","I0617 10:56:02.072215 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.28045\n","INFO:tensorflow:loss = 0.5648789, step = 5700 (78.098 sec)\n","I0617 10:56:02.073129 140626870351744 basic_session_run_hooks.py:260] loss = 0.5648789, step = 5700 (78.098 sec)\n","INFO:tensorflow:global_step/sec: 1.27811\n","I0617 10:57:20.312947 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27811\n","INFO:tensorflow:loss = 0.63451624, step = 5800 (78.241 sec)\n","I0617 10:57:20.314349 140626870351744 basic_session_run_hooks.py:260] loss = 0.63451624, step = 5800 (78.241 sec)\n","INFO:tensorflow:global_step/sec: 1.27549\n","I0617 10:58:38.714401 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27549\n","INFO:tensorflow:loss = 0.47773698, step = 5900 (78.401 sec)\n","I0617 10:58:38.715467 140626870351744 basic_session_run_hooks.py:260] loss = 0.47773698, step = 5900 (78.401 sec)\n","INFO:tensorflow:global_step/sec: 1.27865\n","I0617 10:59:56.921827 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27865\n","INFO:tensorflow:loss = 0.91164, step = 6000 (78.208 sec)\n","I0617 10:59:56.923107 140626870351744 basic_session_run_hooks.py:260] loss = 0.91164, step = 6000 (78.208 sec)\n","INFO:tensorflow:Saving checkpoints for 6037 into training/model.ckpt.\n","I0617 11:00:25.098789 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 6037 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe277e7a2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 11:00:28.855424 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe277e7a2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 11:00:29.297623 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:00:29.328012 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:00:32.116540 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:00:32.128872 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 11:00:32.129200 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:00:32.584873 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:00:32.843135 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 11:00:34.629465 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T11:00:34Z\n","I0617 11:00:34.644524 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T11:00:34Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 11:00:35.304953 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 11:00:35.305617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:00:35.305922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:00:35.306023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:00:35.306049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:00:35.306071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:00:35.306091: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:00:35.306111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:00:35.306130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:00:35.306150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:00:35.306271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:00:35.306580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:00:35.306795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:00:35.306835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:00:35.306849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:00:35.306858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:00:35.306997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:00:35.307308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:00:35.307538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-6037\n","I0617 11:00:35.308426 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-6037\n","INFO:tensorflow:Running local_init_op.\n","I0617 11:00:36.930932 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 11:00:37.119377 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 11:03:49.821595 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.40s)\n","I0617 11:03:50.224916 140623412950784 coco_tools.py:131] DONE (t=0.40s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.86s).\n","Accumulating evaluation results...\n","DONE (t=2.47s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673\n","INFO:tensorflow:Finished evaluation at 2020-06-17-11:04:10\n","I0617 11:04:10.349214 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-11:04:10\n","INFO:tensorflow:Saving dict for global step 6037: DetectionBoxes_Precision/mAP = 0.36628962, DetectionBoxes_Precision/mAP (large) = 0.0186822, DetectionBoxes_Precision/mAP (medium) = 0.3246763, DetectionBoxes_Precision/mAP (small) = 0.3728835, DetectionBoxes_Precision/mAP@.50IOU = 0.7551322, DetectionBoxes_Precision/mAP@.75IOU = 0.2948928, DetectionBoxes_Recall/AR@1 = 0.27427647, DetectionBoxes_Recall/AR@10 = 0.52155435, DetectionBoxes_Recall/AR@100 = 0.55846995, DetectionBoxes_Recall/AR@100 (large) = 0.67333335, DetectionBoxes_Recall/AR@100 (medium) = 0.61183614, DetectionBoxes_Recall/AR@100 (small) = 0.54981256, Loss/BoxClassifierLoss/classification_loss = 0.1610607, Loss/BoxClassifierLoss/localization_loss = 0.12631583, Loss/RPNLoss/localization_loss = 0.028940981, Loss/RPNLoss/objectness_loss = 0.046191916, Loss/total_loss = 0.36250928, global_step = 6037, learning_rate = 0.0003, loss = 0.36250928\n","I0617 11:04:10.349525 140626870351744 estimator.py:2049] Saving dict for global step 6037: DetectionBoxes_Precision/mAP = 0.36628962, DetectionBoxes_Precision/mAP (large) = 0.0186822, DetectionBoxes_Precision/mAP (medium) = 0.3246763, DetectionBoxes_Precision/mAP (small) = 0.3728835, DetectionBoxes_Precision/mAP@.50IOU = 0.7551322, DetectionBoxes_Precision/mAP@.75IOU = 0.2948928, DetectionBoxes_Recall/AR@1 = 0.27427647, DetectionBoxes_Recall/AR@10 = 0.52155435, DetectionBoxes_Recall/AR@100 = 0.55846995, DetectionBoxes_Recall/AR@100 (large) = 0.67333335, DetectionBoxes_Recall/AR@100 (medium) = 0.61183614, DetectionBoxes_Recall/AR@100 (small) = 0.54981256, Loss/BoxClassifierLoss/classification_loss = 0.1610607, Loss/BoxClassifierLoss/localization_loss = 0.12631583, Loss/RPNLoss/localization_loss = 0.028940981, Loss/RPNLoss/objectness_loss = 0.046191916, Loss/total_loss = 0.36250928, global_step = 6037, learning_rate = 0.0003, loss = 0.36250928\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6037: training/model.ckpt-6037\n","I0617 11:04:10.350543 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6037: training/model.ckpt-6037\n","INFO:tensorflow:global_step/sec: 0.329603\n","I0617 11:05:00.317078 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.329603\n","INFO:tensorflow:loss = 0.4680398, step = 6100 (303.395 sec)\n","I0617 11:05:00.317953 140626870351744 basic_session_run_hooks.py:260] loss = 0.4680398, step = 6100 (303.395 sec)\n","INFO:tensorflow:global_step/sec: 1.27484\n","I0617 11:06:18.757988 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27484\n","INFO:tensorflow:loss = 0.55177665, step = 6200 (78.441 sec)\n","I0617 11:06:18.758997 140626870351744 basic_session_run_hooks.py:260] loss = 0.55177665, step = 6200 (78.441 sec)\n","INFO:tensorflow:global_step/sec: 1.27422\n","I0617 11:07:37.237650 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27422\n","INFO:tensorflow:loss = 0.47819647, step = 6300 (78.480 sec)\n","I0617 11:07:37.238792 140626870351744 basic_session_run_hooks.py:260] loss = 0.47819647, step = 6300 (78.480 sec)\n","INFO:tensorflow:global_step/sec: 1.27281\n","I0617 11:08:55.804207 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27281\n","INFO:tensorflow:loss = 0.63258326, step = 6400 (78.566 sec)\n","I0617 11:08:55.805294 140626870351744 basic_session_run_hooks.py:260] loss = 0.63258326, step = 6400 (78.566 sec)\n","INFO:tensorflow:global_step/sec: 1.27425\n","I0617 11:10:14.281913 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27425\n","INFO:tensorflow:loss = 0.44437832, step = 6500 (78.478 sec)\n","I0617 11:10:14.283145 140626870351744 basic_session_run_hooks.py:260] loss = 0.44437832, step = 6500 (78.478 sec)\n","INFO:tensorflow:Saving checkpoints for 6515 into training/model.ckpt.\n","I0617 11:10:25.319551 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 6515 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe26bca3048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 11:10:29.052318 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe26bca3048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 11:10:29.486775 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:10:29.513396 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:10:32.283288 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:10:32.295691 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 11:10:32.296026 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:10:32.749828 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:10:33.011844 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 11:10:34.789821 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T11:10:34Z\n","I0617 11:10:34.805153 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T11:10:34Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 11:10:35.449528 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 11:10:35.450359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:10:35.450795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:10:35.450950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:10:35.450998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:10:35.451029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:10:35.451056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:10:35.451080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:10:35.451104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:10:35.451130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:10:35.451275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:10:35.451738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:10:35.452343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:10:35.452462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:10:35.452487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:10:35.452500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:10:35.452678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:10:35.453146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:10:35.453499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-6515\n","I0617 11:10:35.457295 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-6515\n","INFO:tensorflow:Running local_init_op.\n","I0617 11:10:37.182027 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 11:10:37.395977 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 11:13:53.924344 140623412950784 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.41s)\n","I0617 11:13:54.337912 140623412950784 coco_tools.py:131] DONE (t=0.41s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=16.97s).\n","Accumulating evaluation results...\n","DONE (t=2.58s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.278\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.552\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n","INFO:tensorflow:Finished evaluation at 2020-06-17-11:14:14\n","I0617 11:14:14.663850 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-11:14:14\n","INFO:tensorflow:Saving dict for global step 6515: DetectionBoxes_Precision/mAP = 0.3695197, DetectionBoxes_Precision/mAP (large) = 0.038734496, DetectionBoxes_Precision/mAP (medium) = 0.31747302, DetectionBoxes_Precision/mAP (small) = 0.3767664, DetectionBoxes_Precision/mAP@.50IOU = 0.7503083, DetectionBoxes_Precision/mAP@.75IOU = 0.30404285, DetectionBoxes_Recall/AR@1 = 0.27828375, DetectionBoxes_Recall/AR@10 = 0.5215341, DetectionBoxes_Recall/AR@100 = 0.5604331, DetectionBoxes_Recall/AR@100 (large) = 0.7133333, DetectionBoxes_Recall/AR@100 (medium) = 0.61259484, DetectionBoxes_Recall/AR@100 (small) = 0.551851, Loss/BoxClassifierLoss/classification_loss = 0.15888306, Loss/BoxClassifierLoss/localization_loss = 0.12651473, Loss/RPNLoss/localization_loss = 0.028911384, Loss/RPNLoss/objectness_loss = 0.04832301, Loss/total_loss = 0.3626322, global_step = 6515, learning_rate = 0.0003, loss = 0.3626322\n","I0617 11:14:14.664211 140626870351744 estimator.py:2049] Saving dict for global step 6515: DetectionBoxes_Precision/mAP = 0.3695197, DetectionBoxes_Precision/mAP (large) = 0.038734496, DetectionBoxes_Precision/mAP (medium) = 0.31747302, DetectionBoxes_Precision/mAP (small) = 0.3767664, DetectionBoxes_Precision/mAP@.50IOU = 0.7503083, DetectionBoxes_Precision/mAP@.75IOU = 0.30404285, DetectionBoxes_Recall/AR@1 = 0.27828375, DetectionBoxes_Recall/AR@10 = 0.5215341, DetectionBoxes_Recall/AR@100 = 0.5604331, DetectionBoxes_Recall/AR@100 (large) = 0.7133333, DetectionBoxes_Recall/AR@100 (medium) = 0.61259484, DetectionBoxes_Recall/AR@100 (small) = 0.551851, Loss/BoxClassifierLoss/classification_loss = 0.15888306, Loss/BoxClassifierLoss/localization_loss = 0.12651473, Loss/RPNLoss/localization_loss = 0.028911384, Loss/RPNLoss/objectness_loss = 0.04832301, Loss/total_loss = 0.3626322, global_step = 6515, learning_rate = 0.0003, loss = 0.3626322\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6515: training/model.ckpt-6515\n","I0617 11:14:14.665198 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6515: training/model.ckpt-6515\n","INFO:tensorflow:global_step/sec: 0.324793\n","I0617 11:15:22.170605 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 0.324793\n","INFO:tensorflow:loss = 0.578318, step = 6600 (307.889 sec)\n","I0617 11:15:22.171716 140626870351744 basic_session_run_hooks.py:260] loss = 0.578318, step = 6600 (307.889 sec)\n","INFO:tensorflow:global_step/sec: 1.27739\n","I0617 11:16:40.455049 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27739\n","INFO:tensorflow:loss = 0.6535774, step = 6700 (78.284 sec)\n","I0617 11:16:40.456211 140626870351744 basic_session_run_hooks.py:260] loss = 0.6535774, step = 6700 (78.284 sec)\n","INFO:tensorflow:global_step/sec: 1.27458\n","I0617 11:17:58.911979 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27458\n","INFO:tensorflow:loss = 0.4986852, step = 6800 (78.457 sec)\n","I0617 11:17:58.913001 140626870351744 basic_session_run_hooks.py:260] loss = 0.4986852, step = 6800 (78.457 sec)\n","INFO:tensorflow:global_step/sec: 1.27527\n","I0617 11:19:17.326742 140626870351744 basic_session_run_hooks.py:692] global_step/sec: 1.27527\n","INFO:tensorflow:loss = 0.65695316, step = 6900 (78.415 sec)\n","I0617 11:19:17.327841 140626870351744 basic_session_run_hooks.py:260] loss = 0.65695316, step = 6900 (78.415 sec)\n","INFO:tensorflow:Saving checkpoints for 6988 into training/model.ckpt.\n","I0617 11:20:25.545233 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 6988 into training/model.ckpt.\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe2763b19d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 11:20:29.309710 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe2763b19d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 11:20:29.759766 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:20:29.786705 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:20:32.586834 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:20:32.600023 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 11:20:32.600435 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:20:33.055932 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:20:33.321021 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 11:20:35.126188 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T11:20:35Z\n","I0617 11:20:35.141174 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T11:20:35Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 11:20:35.804460 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 11:20:35.805264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:20:35.805609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:20:35.805702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:20:35.805736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:20:35.805771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:20:35.805800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:20:35.805825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:20:35.805848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:20:35.805871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:20:35.806021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:20:35.806371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:20:35.806593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:20:35.806635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:20:35.806648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:20:35.806657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:20:35.806774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:20:35.807082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:20:35.807316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-6988\n","I0617 11:20:35.808543 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-6988\n","INFO:tensorflow:Running local_init_op.\n","I0617 11:20:37.506978 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 11:20:37.719384 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 11:23:54.009078 140623421343488 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.41s)\n","I0617 11:23:54.422712 140623421343488 coco_tools.py:131] DONE (t=0.41s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=17.09s).\n","Accumulating evaluation results...\n","DONE (t=2.55s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.376\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.277\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.557\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.549\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667\n","INFO:tensorflow:Finished evaluation at 2020-06-17-11:24:14\n","I0617 11:24:14.831433 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-11:24:14\n","INFO:tensorflow:Saving dict for global step 6988: DetectionBoxes_Precision/mAP = 0.36909318, DetectionBoxes_Precision/mAP (large) = 0.024864854, DetectionBoxes_Precision/mAP (medium) = 0.32504582, DetectionBoxes_Precision/mAP (small) = 0.3763382, DetectionBoxes_Precision/mAP@.50IOU = 0.75744766, DetectionBoxes_Precision/mAP@.75IOU = 0.28782046, DetectionBoxes_Recall/AR@1 = 0.27704918, DetectionBoxes_Recall/AR@10 = 0.5191459, DetectionBoxes_Recall/AR@100 = 0.55733657, DetectionBoxes_Recall/AR@100 (large) = 0.6666667, DetectionBoxes_Recall/AR@100 (medium) = 0.61183614, DetectionBoxes_Recall/AR@100 (small) = 0.5485239, Loss/BoxClassifierLoss/classification_loss = 0.15668108, Loss/BoxClassifierLoss/localization_loss = 0.1314576, Loss/RPNLoss/localization_loss = 0.029021006, Loss/RPNLoss/objectness_loss = 0.047359753, Loss/total_loss = 0.3645192, global_step = 6988, learning_rate = 0.0003, loss = 0.3645192\n","I0617 11:24:14.831731 140626870351744 estimator.py:2049] Saving dict for global step 6988: DetectionBoxes_Precision/mAP = 0.36909318, DetectionBoxes_Precision/mAP (large) = 0.024864854, DetectionBoxes_Precision/mAP (medium) = 0.32504582, DetectionBoxes_Precision/mAP (small) = 0.3763382, DetectionBoxes_Precision/mAP@.50IOU = 0.75744766, DetectionBoxes_Precision/mAP@.75IOU = 0.28782046, DetectionBoxes_Recall/AR@1 = 0.27704918, DetectionBoxes_Recall/AR@10 = 0.5191459, DetectionBoxes_Recall/AR@100 = 0.55733657, DetectionBoxes_Recall/AR@100 (large) = 0.6666667, DetectionBoxes_Recall/AR@100 (medium) = 0.61183614, DetectionBoxes_Recall/AR@100 (small) = 0.5485239, Loss/BoxClassifierLoss/classification_loss = 0.15668108, Loss/BoxClassifierLoss/localization_loss = 0.1314576, Loss/RPNLoss/localization_loss = 0.029021006, Loss/RPNLoss/objectness_loss = 0.047359753, Loss/total_loss = 0.3645192, global_step = 6988, learning_rate = 0.0003, loss = 0.3645192\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6988: training/model.ckpt-6988\n","I0617 11:24:14.832724 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6988: training/model.ckpt-6988\n","INFO:tensorflow:Saving checkpoints for 7000 into training/model.ckpt.\n","I0617 11:24:24.250965 140626870351744 basic_session_run_hooks.py:606] Saving checkpoints for 7000 into training/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0617 11:24:27.978397 140626870351744 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fe26d72e268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0617 11:24:28.037600 140626870351744 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fe26d72e268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:Calling model_fn.\n","I0617 11:24:28.470584 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:24:28.497128 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:24:31.687450 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:24:31.700921 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 11:24:31.701327 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:24:32.145251 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:24:32.402846 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0617 11:24:34.222533 140626870351744 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-06-17T11:24:34Z\n","I0617 11:24:34.238128 140626870351744 evaluation.py:255] Starting evaluation at 2020-06-17T11:24:34Z\n","INFO:tensorflow:Graph was finalized.\n","I0617 11:24:34.903126 140626870351744 monitored_session.py:240] Graph was finalized.\n","2020-06-17 11:24:34.903951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:24:34.904442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:24:34.904564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:24:34.904606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:24:34.904645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:24:34.904677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:24:34.904709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:24:34.904735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:24:34.904762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:24:34.904940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:24:34.905490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:24:34.905911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:24:34.905963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:24:34.905983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:24:34.905997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:24:34.906173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:24:34.906695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:24:34.907059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7000\n","I0617 11:24:34.908281 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-7000\n","INFO:tensorflow:Running local_init_op.\n","I0617 11:24:36.677967 140626870351744 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0617 11:24:36.908327 140626870351744 session_manager.py:502] Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0617 11:27:52.567077 140623421343488 coco_tools.py:109] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.40s)\n","I0617 11:27:52.969794 140623421343488 coco_tools.py:131] DONE (t=0.40s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=17.06s).\n","Accumulating evaluation results...\n","DONE (t=2.54s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.528\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.574\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n","INFO:tensorflow:Finished evaluation at 2020-06-17-11:28:13\n","I0617 11:28:13.336186 140626870351744 evaluation.py:275] Finished evaluation at 2020-06-17-11:28:13\n","INFO:tensorflow:Saving dict for global step 7000: DetectionBoxes_Precision/mAP = 0.32500675, DetectionBoxes_Precision/mAP (large) = 0.030233093, DetectionBoxes_Precision/mAP (medium) = 0.28287673, DetectionBoxes_Precision/mAP (small) = 0.33251557, DetectionBoxes_Precision/mAP@.50IOU = 0.7287303, DetectionBoxes_Precision/mAP@.75IOU = 0.21318778, DetectionBoxes_Recall/AR@1 = 0.24948391, DetectionBoxes_Recall/AR@10 = 0.49069014, DetectionBoxes_Recall/AR@100 = 0.5347703, DetectionBoxes_Recall/AR@100 (large) = 0.6333333, DetectionBoxes_Recall/AR@100 (medium) = 0.5742033, DetectionBoxes_Recall/AR@100 (small) = 0.5283271, Loss/BoxClassifierLoss/classification_loss = 0.15551552, Loss/BoxClassifierLoss/localization_loss = 0.1428248, Loss/RPNLoss/localization_loss = 0.029262757, Loss/RPNLoss/objectness_loss = 0.048093494, Loss/total_loss = 0.37569618, global_step = 7000, learning_rate = 0.0003, loss = 0.37569618\n","I0617 11:28:13.336463 140626870351744 estimator.py:2049] Saving dict for global step 7000: DetectionBoxes_Precision/mAP = 0.32500675, DetectionBoxes_Precision/mAP (large) = 0.030233093, DetectionBoxes_Precision/mAP (medium) = 0.28287673, DetectionBoxes_Precision/mAP (small) = 0.33251557, DetectionBoxes_Precision/mAP@.50IOU = 0.7287303, DetectionBoxes_Precision/mAP@.75IOU = 0.21318778, DetectionBoxes_Recall/AR@1 = 0.24948391, DetectionBoxes_Recall/AR@10 = 0.49069014, DetectionBoxes_Recall/AR@100 = 0.5347703, DetectionBoxes_Recall/AR@100 (large) = 0.6333333, DetectionBoxes_Recall/AR@100 (medium) = 0.5742033, DetectionBoxes_Recall/AR@100 (small) = 0.5283271, Loss/BoxClassifierLoss/classification_loss = 0.15551552, Loss/BoxClassifierLoss/localization_loss = 0.1428248, Loss/RPNLoss/localization_loss = 0.029262757, Loss/RPNLoss/objectness_loss = 0.048093494, Loss/total_loss = 0.37569618, global_step = 7000, learning_rate = 0.0003, loss = 0.37569618\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: training/model.ckpt-7000\n","I0617 11:28:13.337459 140626870351744 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7000: training/model.ckpt-7000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0617 11:28:13.338137 140626870351744 exporter.py:410] Performing the final export in the end of training.\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:606: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0617 11:28:13.345140 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:606: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","INFO:tensorflow:Calling model_fn.\n","I0617 11:28:13.506196 140626870351744 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:28:13.517227 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:28:16.295150 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:28:16.309286 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 11:28:16.309785 140626870351744 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:28:16.744073 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:28:16.995217 140626870351744 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:387: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0617 11:28:17.558674 140626870351744 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:387: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0617 11:28:17.955934 140626870351744 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0617 11:28:17.956218 140626870351744 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0617 11:28:17.956687 140626870351744 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0617 11:28:17.956816 140626870351744 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0617 11:28:17.956911 140626870351744 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0617 11:28:17.956981 140626870351744 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0617 11:28:17.957047 140626870351744 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2020-06-17 11:28:17.957605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:28:17.957976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:28:17.958066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:28:17.958096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:28:17.958118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:28:17.958142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:28:17.958162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:28:17.958181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:28:17.958202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:28:17.958317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:28:17.958633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:28:17.958879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:28:17.958935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:28:17.958950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:28:17.958959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:28:17.959090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:28:17.959389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:28:17.959619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7000\n","I0617 11:28:17.962056 140626870351744 saver.py:1284] Restoring parameters from training/model.ckpt-7000\n","INFO:tensorflow:Assets added to graph.\n","I0617 11:28:18.884246 140626870351744 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0617 11:28:18.884480 140626870351744 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1592393293'/saved_model.pb\n","I0617 11:28:20.679733 140626870351744 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1592393293'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 0.8255045.\n","I0617 11:28:21.186152 140626870351744 estimator.py:371] Loss for final step: 0.8255045.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MQY54srv7NSL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"ok","timestamp":1592393311226,"user_tz":-600,"elapsed":168233,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"8b36b0e0-b83f-4197-87d5-14e3e8cbaace"},"source":["!ls {model_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["checkpoint\n","eval_0\n","events.out.tfevents.1592384388.db6e00fb63e1\n","export\n","graph.pbtxt\n","model.ckpt-5555.data-00000-of-00001\n","model.ckpt-5555.index\n","model.ckpt-5555.meta\n","model.ckpt-6037.data-00000-of-00001\n","model.ckpt-6037.index\n","model.ckpt-6037.meta\n","model.ckpt-6515.data-00000-of-00001\n","model.ckpt-6515.index\n","model.ckpt-6515.meta\n","model.ckpt-6988.data-00000-of-00001\n","model.ckpt-6988.index\n","model.ckpt-6988.meta\n","model.ckpt-7000.data-00000-of-00001\n","model.ckpt-7000.index\n","model.ckpt-7000.meta\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4y32QymeiqDB","colab_type":"text"},"source":["##Task-4:  Freezing a trained model and export it for inference\n"]},{"cell_type":"markdown","metadata":{"id":"7b1cB69J7-Qh","colab_type":"text"},"source":["### Step: 10 Exporting a Trained Inference Graph"]},{"cell_type":"code","metadata":{"id":"ZhQu9lWK71fS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592394861916,"user_tz":-600,"elapsed":27128,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"4b5e9a90-49cc-4590-a8d1-4877245408a2"},"source":["import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["training/model.ckpt-7000\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:150: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0617 11:54:04.371880 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0617 11:54:04.379477 140158920451968 deprecation.py:323] From /content/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:348: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0617 11:54:04.382447 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:348: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0617 11:54:04.382739 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2154: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0617 11:54:04.422861 140158920451968 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:2154: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0617 11:54:04.438835 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0617 11:54:04.460829 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:54:04.470107 140158920451968 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0617 11:54:04.472759 140158920451968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0617 11:54:07.432069 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:54:07.438727 140158920451968 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","W0617 11:54:07.439115 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:54:07.452192 140158920451968 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:147: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0617 11:54:07.452548 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:147: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0617 11:54:07.452667 140158920451968 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:136: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0617 11:54:07.502345 140158920451968 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:136: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:185: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","W0617 11:54:07.935282 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:185: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:54:07.935662 140158920451968 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0617 11:54:08.197104 140158920451968 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:712: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0617 11:54:08.337769 140158920451968 deprecation.py:506] From /content/models/research/object_detection/utils/ops.py:712: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use the `axis` argument instead\n","W0617 11:54:08.405458 140158920451968 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use the `axis` argument instead\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:231: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0617 11:54:09.048885 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:231: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0617 11:54:09.049160 140158920451968 deprecation.py:323] From /content/models/research/object_detection/exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:361: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0617 11:54:09.052310 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:361: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0617 11:54:09.052496 140158920451968 deprecation.py:323] From /content/models/research/object_detection/exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0617 11:54:09.053572 140158920451968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","232 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/64.25m params)\n","  Conv (--/4.72m params)\n","    Conv/biases (512, 512/512 params)\n","    Conv/weights (3x3x1024x512, 4.72m/4.72m params)\n","  FirstStageBoxPredictor (--/36.94k params)\n","    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n","      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n","      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n","    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n","      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n","      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","  FirstStageFeatureExtractor (--/42.39m params)\n","    FirstStageFeatureExtractor/resnet_v1_101 (--/42.39m params)\n","      FirstStageFeatureExtractor/resnet_v1_101/block1 (--/212.99k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1 (--/73.73k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1 (--/73.73k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1 (--/4.10k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights (1x1x64x64, 4.10k/4.10k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2 (--/36.86k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3 (--/16.38k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut (--/16.38k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2 (--/69.63k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1 (--/69.63k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1 (--/16.38k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2 (--/36.86k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3 (--/16.38k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3 (--/69.63k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1 (--/69.63k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1 (--/16.38k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2 (--/36.86k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3 (--/16.38k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n","      FirstStageFeatureExtractor/resnet_v1_101/block2 (--/1.21m params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1 (--/376.83k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1 (--/376.83k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1 (--/32.77k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights (1x1x256x128, 32.77k/32.77k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2 (--/147.46k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut (--/131.07k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2 (--/278.53k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1 (--/278.53k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2 (--/147.46k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3 (--/278.53k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1 (--/278.53k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2 (--/147.46k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4 (--/278.53k params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1 (--/278.53k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2 (--/147.46k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3 (--/65.54k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n","      FirstStageFeatureExtractor/resnet_v1_101/block3 (--/26.02m params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1 (--/1.51m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1 (--/1.51m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1 (--/131.07k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights (1x1x512x256, 131.07k/131.07k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut (--/524.29k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9 (--/1.11m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1 (--/1.11m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2 (--/589.82k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3 (--/262.14k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n","      FirstStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n","        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n","          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n","            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n","      FirstStageFeatureExtractor/resnet_v1_101/conv1 (--/9.41k params)\n","        FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/resnet_v1_101/conv1/weights (7x7x3x64, 9.41k/9.41k params)\n","  SecondStageBoxPredictor (--/2.15m params)\n","    SecondStageBoxPredictor/class_predictions (--/18.45k params)\n","      SecondStageBoxPredictor/class_predictions/biases (18, 18/18 params)\n","      SecondStageBoxPredictor/class_predictions/weights (1x1x1024x18, 18.43k/18.43k params)\n","    SecondStageBoxPredictor/reduce_depth (--/2.10m params)\n","      SecondStageBoxPredictor/reduce_depth/biases (1024, 1.02k/1.02k params)\n","      SecondStageBoxPredictor/reduce_depth/weights (1x1x2048x1024, 2.10m/2.10m params)\n","    SecondStageBoxPredictor/refined_locations (--/36.90k params)\n","      SecondStageBoxPredictor/refined_locations/biases (36, 36/36 params)\n","      SecondStageBoxPredictor/refined_locations/weights (1x1x1024x36, 36.86k/36.86k params)\n","  SecondStageFeatureExtractor (--/14.94m params)\n","    SecondStageFeatureExtractor/resnet_v1_101 (--/14.94m params)\n","      SecondStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n","        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n","          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n","        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n","          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n","        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n","          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n","            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n","              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n","\n","======================End of Report==========================\n","232 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/686.55k flops)\n","  SecondStageBoxPredictor/map/while/AddN (345.60k/345.60k flops)\n","  SecondStageBoxPredictor/map_1/while/AddN (172.80k/172.80k flops)\n","  SecondStageBoxPredictor/map/while/Mean (43.20k/43.20k flops)\n","  SecondStageBoxPredictor/map/while/truediv_12 (43.20k/43.20k flops)\n","  SecondStageBoxPredictor/map_1/while/Mean (21.60k/21.60k flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_12 (21.60k/21.60k flops)\n","  SecondStageBoxPredictor/map_1/while/mul_18 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_1 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_10 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_11 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_12 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_13 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_14 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_15 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_16 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_17 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_27 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_19 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_2 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_20 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_21 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_22 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_23 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_24 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_25 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_26 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_28 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_10 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_11 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_2 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_3 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_4 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_5 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_6 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_7 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_8 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_9 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_1 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_10 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_11 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_2 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_3 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_4 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_5 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_6 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_8 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_9 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_6 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_7 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_8 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_9 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_1 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_10 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_11 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_2 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_3 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_4 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_5 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_6 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_7 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_8 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/truediv_9 (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n","  map_1/while/mul (300/300 flops)\n","  map_1/while/mul_1 (300/300 flops)\n","  map_1/while/mul_2 (300/300 flops)\n","  map_1/while/mul_3 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_7 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_29 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_3 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_30 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_31 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_32 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_33 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_34 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_35 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_4 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_5 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_6 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/truediv_7 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_8 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/mul_9 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_1 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_10 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_11 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_2 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_3 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_4 (300/300 flops)\n","  SecondStageBoxPredictor/map_1/while/sub_5 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_17 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub_1 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_24 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_23 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_22 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_21 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_20 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_2 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_19 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_18 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/sub (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_16 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_15 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_14 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_13 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_12 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_11 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_10 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_1 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_26 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_9 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_8 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_7 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_6 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_5 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_4 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_35 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_34 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_33 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_31 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_30 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_3 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_29 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_25 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_28 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_27 (300/300 flops)\n","  SecondStageBoxPredictor/map/while/mul_32 (300/300 flops)\n","  GridAnchorGenerator/truediv (12/12 flops)\n","  GridAnchorGenerator/mul_2 (12/12 flops)\n","  GridAnchorGenerator/mul_1 (12/12 flops)\n","  GridAnchorGenerator/mul (12/12 flops)\n","  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n","  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n","  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  map/while/Less_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  map_1/while/Less_1 (1/1 flops)\n","  map_1/while/Less (1/1 flops)\n","  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/mul (1/1 flops)\n","  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n","  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n","  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  GridAnchorGenerator/mul_7 (1/1 flops)\n","  GridAnchorGenerator/mul_8 (1/1 flops)\n","  GridAnchorGenerator/zeros/Less (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/Greater (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/Maximum (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/Minimum (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/mul_1 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/mul_2 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/mul_3 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/truediv (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/truediv_1 (1/1 flops)\n","  SecondStageBoxPredictor/map/while/Less (1/1 flops)\n","  SecondStageBoxPredictor/map/while/Less_1 (1/1 flops)\n","  SecondStageBoxPredictor/map_1/while/Less_1 (1/1 flops)\n","  SecondStageBoxPredictor/map_1/while/Less (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  SecondStageBoxPredictor/mul_1 (1/1 flops)\n","  SecondStageBoxPredictor/mul (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0617 11:54:10.712829 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","2020-06-17 11:54:11.943492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-17 11:54:11.950469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:11.950940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:54:11.954910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:54:11.960871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:54:11.962800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:54:11.963172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:54:11.968465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:54:11.973618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:54:11.978670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:54:11.978812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:11.979334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:11.979736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:54:11.985135: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-06-17 11:54:11.985344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x320b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-17 11:54:11.985375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-17 11:54:12.084795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:12.085463: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x320af40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-17 11:54:12.085495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-17 11:54:12.085786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:12.086329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:54:12.086414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:54:12.086442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:54:12.086475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:54:12.086497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:54:12.086522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:54:12.086548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:54:12.086578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:54:12.086693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:12.087227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:12.087619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:54:12.087685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:54:12.088758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:54:12.088785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:54:12.088796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:54:12.088958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:12.089447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:12.089920: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-17 11:54:12.089970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7000\n","I0617 11:54:12.091634 140158920451968 saver.py:1284] Restoring parameters from training/model.ckpt-7000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0617 11:54:15.275730 140158920451968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-06-17 11:54:15.985182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:15.985715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:54:15.985801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:54:15.985826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:54:15.985850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:54:15.985872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:54:15.985893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:54:15.985930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:54:15.985951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:54:15.986070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:15.986547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:15.986942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:54:15.986983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:54:15.986997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:54:15.987006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:54:15.987131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:15.987632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:15.988040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7000\n","I0617 11:54:15.989352 140158920451968 saver.py:1284] Restoring parameters from training/model.ckpt-7000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0617 11:54:17.091264 140158920451968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0617 11:54:17.091529 140158920451968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 532 variables.\n","I0617 11:54:17.663572 140158920451968 graph_util_impl.py:334] Froze 532 variables.\n","INFO:tensorflow:Converted 532 variables to const ops.\n","I0617 11:54:17.938369 140158920451968 graph_util_impl.py:394] Converted 532 variables to const ops.\n","2020-06-17 11:54:18.572772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:18.573298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-17 11:54:18.573416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-17 11:54:18.573445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-17 11:54:18.573473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-17 11:54:18.573515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-17 11:54:18.573540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-17 11:54:18.573563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-17 11:54:18.573587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-17 11:54:18.573699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:18.574382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:18.574984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-17 11:54:18.575040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-17 11:54:18.575057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-17 11:54:18.575070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-17 11:54:18.575283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:18.576088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-17 11:54:18.576729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:259: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0617 11:54:19.516744 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:259: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0617 11:54:19.517249 140158920451968 deprecation.py:323] From /content/models/research/object_detection/exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:268: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","W0617 11:54:19.517635 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:268: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:274: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","W0617 11:54:19.517863 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:274: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","INFO:tensorflow:No assets to save.\n","I0617 11:54:19.518169 140158920451968 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0617 11:54:19.518273 140158920451968 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n","I0617 11:54:20.448054 140158920451968 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0617 11:54:20.571968 140158920451968 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n","I0617 11:54:20.572267 140158920451968 config_util.py:182] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hnHLjMbXDZ5G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1592395555917,"user_tz":-600,"elapsed":2422,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"536e8929-df5c-4be3-f04c-3827d87a10fe"},"source":["!ls {output_directory}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\n","frozen_inference_graph.pb\tmodel.ckpt.meta\n","model.ckpt.data-00000-of-00001\tpipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rfwp6BrFC2qQ","colab_type":"text"},"source":["### Step 11: Use frozen model for inference."]},{"cell_type":"code","metadata":{"id":"4pdDFjp9DS2l","colab_type":"code","colab":{}},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2JfeX0QSmiV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1592395558670,"user_tz":-600,"elapsed":2827,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"63e9a041-5bec-49fa-9e57-792070390483"},"source":["!ls -alh {pb_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 190M Jun 17 11:54 /content/models/research/object_detection/fine_tuned_model/frozen_inference_graph.pb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Maem5Yv_FCn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1592395558671,"user_tz":-600,"elapsed":2528,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"4506c4c4-4c43-4e42-f248-e7d64e4d5021"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  '/content/gdrive/My Drive/A3 test/img'\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['/content/gdrive/My Drive/A3 test/img/resized_C59P20thinF_IMG_20150803_111244_cell_188.png', '/content/gdrive/My Drive/A3 test/img/resized_C39P4thinF_original_IMG_20150622_110900_cell_19.png', '/content/gdrive/My Drive/A3 test/img/resized_C39P4thinF_original_IMG_20150622_110115_cell_118.png']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xEHFCsWxFCRz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592395569939,"user_tz":-600,"elapsed":10280,"user":{"displayName":"Alifia Cesarina Harmadi","photoUrl":"","userId":"00710599022801911658"}},"outputId":"c8240c33-f08d-44f0-b532-ab304ea47ee1"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","num_classes = 1\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","  #load images\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"GioPUIRjFDYX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}